{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "african-pocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import pickle5\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from pysurvival.models.semi_parametric import CoxPHModel\n",
    "from pysurvival.utils.display import display_loss_values\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pysurvival.utils.display import compare_to_actual\n",
    "from pysurvival.utils import save_model, load_model\n",
    "from pysurvival.utils.sklearn_adapter import sklearn_adapter\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import auc, r2_score\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import resample\n",
    "from lifelines.utils import concordance_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "prescribed-method",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>life_time</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_end</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>distance_center_km</th>\n",
       "      <th>Station_Name</th>\n",
       "      <th>weekday_b</th>\n",
       "      <th>weekday_b_name</th>\n",
       "      <th>hour_b</th>\n",
       "      <th>...</th>\n",
       "      <th>near_inactivity_6H</th>\n",
       "      <th>near_charge_events_6H</th>\n",
       "      <th>service</th>\n",
       "      <th>entertainment</th>\n",
       "      <th>food</th>\n",
       "      <th>childcare</th>\n",
       "      <th>medical</th>\n",
       "      <th>education</th>\n",
       "      <th>parking</th>\n",
       "      <th>waste-management</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>928.5</td>\n",
       "      <td>2018-01-31 19:51:00</td>\n",
       "      <td>2018-02-01 11:19:30</td>\n",
       "      <td>40.018482</td>\n",
       "      <td>-105.281066</td>\n",
       "      <td>0.152203</td>\n",
       "      <td>COMM VITALITY / 1104 SPRUCE1</td>\n",
       "      <td>2</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.057343</td>\n",
       "      <td>0.109796</td>\n",
       "      <td>0.073649</td>\n",
       "      <td>3.517121</td>\n",
       "      <td>0.466518</td>\n",
       "      <td>0.631771</td>\n",
       "      <td>0.021832</td>\n",
       "      <td>1.145959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>363.5</td>\n",
       "      <td>2018-02-01 14:03:00</td>\n",
       "      <td>2018-02-01 20:06:30</td>\n",
       "      <td>40.018482</td>\n",
       "      <td>-105.281066</td>\n",
       "      <td>0.152203</td>\n",
       "      <td>COMM VITALITY / 1104 SPRUCE1</td>\n",
       "      <td>3</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.057343</td>\n",
       "      <td>0.109796</td>\n",
       "      <td>0.073649</td>\n",
       "      <td>3.517121</td>\n",
       "      <td>0.466518</td>\n",
       "      <td>0.631771</td>\n",
       "      <td>0.021832</td>\n",
       "      <td>1.145959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6828.5</td>\n",
       "      <td>2018-02-01 21:15:00</td>\n",
       "      <td>2018-02-06 15:03:30</td>\n",
       "      <td>40.018482</td>\n",
       "      <td>-105.281066</td>\n",
       "      <td>0.152203</td>\n",
       "      <td>COMM VITALITY / 1104 SPRUCE1</td>\n",
       "      <td>3</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.057343</td>\n",
       "      <td>0.109796</td>\n",
       "      <td>0.073649</td>\n",
       "      <td>3.517121</td>\n",
       "      <td>0.466518</td>\n",
       "      <td>0.631771</td>\n",
       "      <td>0.021832</td>\n",
       "      <td>1.145959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   life_time      datetime_start        datetime_end   latitude   longitude  \\\n",
       "0      928.5 2018-01-31 19:51:00 2018-02-01 11:19:30  40.018482 -105.281066   \n",
       "1      363.5 2018-02-01 14:03:00 2018-02-01 20:06:30  40.018482 -105.281066   \n",
       "2     6828.5 2018-02-01 21:15:00 2018-02-06 15:03:30  40.018482 -105.281066   \n",
       "\n",
       "   distance_center_km                  Station_Name  weekday_b weekday_b_name  \\\n",
       "0            0.152203  COMM VITALITY / 1104 SPRUCE1          2      Wednesday   \n",
       "1            0.152203  COMM VITALITY / 1104 SPRUCE1          3       Thursday   \n",
       "2            0.152203  COMM VITALITY / 1104 SPRUCE1          3       Thursday   \n",
       "\n",
       "   hour_b  ...  near_inactivity_6H  near_charge_events_6H   service  \\\n",
       "0      19  ...                 0.0                      0  0.057343   \n",
       "1      14  ...                 0.0                      0  0.057343   \n",
       "2      21  ...                 0.0                      0  0.057343   \n",
       "\n",
       "   entertainment      food  childcare   medical  education   parking  \\\n",
       "0       0.109796  0.073649   3.517121  0.466518   0.631771  0.021832   \n",
       "1       0.109796  0.073649   3.517121  0.466518   0.631771  0.021832   \n",
       "2       0.109796  0.073649   3.517121  0.466518   0.631771  0.021832   \n",
       "\n",
       "   waste-management  \n",
       "0          1.145959  \n",
       "1          1.145959  \n",
       "2          1.145959  \n",
       "\n",
       "[3 rows x 71 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../data/ut_poiV6.pkl\", \"rb\") as fh:\n",
    "    df = pickle5.load(fh)\n",
    "    \n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quarterly-sellers",
   "metadata": {},
   "source": [
    "### Remove outliers & nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exceptional-adoption",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "friendly-ending",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMM VITALITY / 1104 SPRUCE1: 57 (4.4 %)\n",
      "COMM VITALITY / 1000WALNUT: 48 (3.32 %)\n",
      "BOULDER / REC CENTER: 40 (3.51 %)\n",
      "BOULDER / BASELINE ST1: 42 (3.53 %)\n",
      "BOULDER / ATRIUM ST1: 65 (6.58 %)\n",
      "BOULDER / ALPINE ST1: 32 (8.96 %)\n",
      "COMM VITALITY / 1400 WALNUT1: 38 (7.29 %)\n",
      "BOULDER / FACILITIES ST1: 84 (16.28 %)\n",
      "COMM VITALITY / 1500PEARL: 41 (4.5 %)\n",
      "BOULDER / JUNCTION ST1: 35 (9.97 %)\n",
      "COMM VITALITY / BOULDER JCTN: 40 (5.28 %)\n",
      "COMM VITALITY / 1100WALNUT1: 39 (3.51 %)\n",
      "BOULDER / N BOULDER REC 1: 29 (2.07 %)\n",
      "BOULDER / BOULDER PARK: 8 (4.55 %)\n",
      "COMM VITALITY / 2200 BROADWAY1: 0 (0.0 %)\n",
      "BOULDER / EAST REC: 23 (5.42 %)\n",
      "BOULDERJUNCTION / JUNCTION ST1: 3 (3.0 %)\n",
      "\n",
      "The total amount of lost events: 624 (4.91 %)\n"
     ]
    }
   ],
   "source": [
    "# remove outliers\n",
    "drop_index = [] # list of indexes to keep\n",
    "names = df['Station_Name'].unique()\n",
    "\n",
    "for name in names:\n",
    "    temp = df[df['Station_Name'] == name]\n",
    "    # Get interquantile ranges\n",
    "    Q1, Q3 = temp.life_time.quantile([0.25, 0.75])\n",
    "    IQR = Q3-Q1\n",
    "    minimum = Q1 - 1.5*IQR\n",
    "    maximum = Q3 + 1.5*IQR\n",
    "    # Define observations which should be removed\n",
    "    temp2 = df[(df['life_time'] < minimum) | (df['life_time'] > maximum) &\n",
    "                  (df['Station_Name'] == name)]\n",
    "    print(\"{n}: {s} ({p} %)\".format(n=name, \n",
    "                                    s=temp2.shape[0], \n",
    "                                    p=round((temp2.shape[0]/temp.shape[0])*100,2)))\n",
    "    # Add the indexes which should be dropped\n",
    "    drop_index.extend(list(temp2.index))\n",
    "    \n",
    "print(\"\\nThe total amount of lost events: {n} ({p} %)\".format(n=len(drop_index), \n",
    "                                                              p=round(len(drop_index)/df.shape[0]*100,2)))\n",
    "\n",
    "df = df.drop(drop_index)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "czech-carrier",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12075, 71)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-heating",
   "metadata": {},
   "source": [
    "### Focus stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "preceding-olympus",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_subset = ['BOULDER / N BOULDER REC 1', 'COMM VITALITY / 1000WALNUT', \n",
    "        'COMM VITALITY / 1104 SPRUCE1', 'BOULDER / BASELINE ST1']\n",
    "\n",
    "df = df[df['Station_Name'].isin(station_subset)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-drunk",
   "metadata": {},
   "source": [
    "### Prepare data for SA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-chance",
   "metadata": {},
   "source": [
    "As we are doing SA we need a column which specifies if an event occured at the given time. As all data observations in the dataset are events it is a very simple procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "interesting-shower",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['event'] = np.ones(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "south-aging",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tod'] = df['hour_b'].apply(hour_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "solar-technical",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['tod'] != 'Night']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daily-investing",
   "metadata": {},
   "source": [
    "### Adding dummies\n",
    "We define `X`, the features, `T`, the time column and `E` the event columns. First though we need to dummify the categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "hairy-development",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features\n",
    "columns_categorical = ['weekday_b_name','tod','Station_Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "solar-compound",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=columns_categorical, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scenic-mills",
   "metadata": {},
   "source": [
    "## Modeling features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-cloud",
   "metadata": {},
   "source": [
    "To make coding easier the names of the models are changed:\n",
    "- M1: Baseline\n",
    "- M5: Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dressed-vegetation",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_column = 'life_time'\n",
    "event_column = 'event'\n",
    "\n",
    "## M1\n",
    "features1 = ['weekday_b_name_Monday', 'weekday_b_name_Saturday',\n",
    "             'weekday_b_name_Sunday', 'weekday_b_name_Thursday',\n",
    "             'weekday_b_name_Tuesday', 'weekday_b_name_Wednesday',\n",
    "             'tod_Evening','tod_Midday', 'tod_Morning',\n",
    "             'Station_Name_BOULDER / N BOULDER REC 1',\n",
    "             'Station_Name_COMM VITALITY / 1000WALNUT',\n",
    "             'Station_Name_COMM VITALITY / 1104 SPRUCE1'] # dow + tod\n",
    "\n",
    "## M5\n",
    "features5_cat = ['weekday_b_name_Monday', 'weekday_b_name_Saturday',\n",
    "                 'weekday_b_name_Sunday', 'weekday_b_name_Thursday',\n",
    "                 'weekday_b_name_Tuesday', 'weekday_b_name_Wednesday',\n",
    "                 'tod_Evening','tod_Midday', 'tod_Morning',\n",
    "                 'Station_Name_BOULDER / N BOULDER REC 1',\n",
    "                 'Station_Name_COMM VITALITY / 1000WALNUT',\n",
    "                 'Station_Name_COMM VITALITY / 1104 SPRUCE1']\n",
    "features5_con = ['lag1', 'lag2', 'lag3','near_charge_time_4H', 'near_charge_energy_4H',\n",
    "                 'charge_time_4H', 'charge_energy_4H','service', 'entertainment', 'food', \n",
    "                 'childcare', 'medical', 'education','parking', 'waste-management'] # dow + agg. tod + lag + activ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "duplicate-charity",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get point predictions\n",
    "def point_pred(model, X_test, X_train):\n",
    "    T_pred = []\n",
    "    T_pred_train = []\n",
    "    # Get survival curves\n",
    "    cph_pred = model.predict_survival(X_test)\n",
    "    cph_pred_train = model.predict_survival(X_train)\n",
    "    # get times of survival prediction\n",
    "    time = model.times\n",
    "    # test\n",
    "    for i in range(0,len(cph_pred)):\n",
    "        T_pred.append(auc(time,cph_pred[i]))\n",
    "    # train\n",
    "    for i in range(0,len(cph_pred_train)):\n",
    "        T_pred_train.append(auc(time,cph_pred_train[i]))\n",
    "    \n",
    "    return T_pred, T_pred_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dental-persian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "stuffed-essay",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To test model\n",
    "def test_model(y_test, y_pred):\n",
    "    MAE = metrics.mean_absolute_error(y_test, y_pred)\n",
    "    #print('MAE (Mean Absolute Error):', MAE)\n",
    "    MSE = metrics.mean_squared_error(y_test, y_pred)\n",
    "    #print('MSE (Mean Squared Error):', MSE)\n",
    "    RMSE = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "    #print('RMSE (Root Mean Squared Error):', RMSE)\n",
    "    MAPE = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    \n",
    "    NRMSE = RMSE/np.mean(y_test)\n",
    "    return MAE, RMSE, MSE, MAPE, NRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "indonesian-parcel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to save results in \n",
    "results = {}\n",
    "\n",
    "#data split\n",
    "split = 0.8\n",
    "\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "regularization = [0.01, 0.1, 1.0]\n",
    "\n",
    "# order data\n",
    "df = df.sort_values(by=['datetime_start'])\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stock-remains",
   "metadata": {},
   "source": [
    "#### CPH - Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "lightweight-aurora",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model fitted\n",
      "Best param. lr: 0.1 l2_reg: 0.01\n",
      "0.6333332053197331\n",
      "Model tested\n"
     ]
    }
   ],
   "source": [
    "results['M1'] = {}\n",
    "# define data\n",
    "X = df[features1]\n",
    "X_train, X_test = np.split(X, [int(split * len(df))])\n",
    "T_train, T_test = np.split(df[time_column], [int(split * len(df))])\n",
    "E_train, E_test = np.split(df[event_column], [int(split * len(df))])\n",
    "\n",
    "##############################################################################\n",
    "### Find most optimal parameters for every station\n",
    "best_c = -1\n",
    "best_lear = None\n",
    "best_regu = None\n",
    "best_model = None\n",
    "fails = {}\n",
    "\n",
    "total_it = len(learning_rates)*len(regularization)\n",
    "i=0\n",
    "\n",
    "# loop over parameters\n",
    "for lear in learning_rates:\n",
    "    for regu in regularization:\n",
    "        cv_res = []\n",
    "    #try\n",
    "        kf = KFold(n_splits=3, random_state=42, shuffle=False)\n",
    "        for train_index, test_index in kf.split(X_train):\n",
    "            cph = CoxPHModel()\n",
    "            cph.fit(X_train.loc[train_index], T_train.loc[train_index], E_train.loc[train_index],\n",
    "                    lr=lear, l2_reg = regu, init_method='zeros', max_iter=800, verbose=False)\n",
    "\n",
    "            #point pred\n",
    "            point_predictions = point_pred_single(cph,X_train.loc[test_index])\n",
    "            # c-index\n",
    "            c_temp = concordance_index(T_train.loc[test_index], point_predictions)\n",
    "\n",
    "            cv_res.append(c_temp)\n",
    "        if np.mean(c_temp) >= best_c:\n",
    "            print(\"NEW BEST!!\", i)\n",
    "            best_lear = lear\n",
    "            best_regu = regu\n",
    "            best_c = np.mean(c_temp)\n",
    "    #except:\n",
    "        print(\"FAIL, lr:\", lear, \" l2:\", regu)   \n",
    "        i+=1\n",
    "        print(round(i/total_it,2), \"  \", end='')\n",
    "print(\"Parameter tuning done.\")\n",
    "print(\"Params: learning: {} regularization: {}\".format(best_lear,best_regu))\n",
    "\n",
    "##############################################################################        \n",
    "### Get predictions\n",
    "reg = CoxPHModel()\n",
    "reg.fit(X_train, T_train, E_train, lr=best_lear, l2_reg=best_regu,\n",
    "        init_method='zeros', max_iter=800, verbose=False)\n",
    "print(\"Model fitted\")   \n",
    "print(\"Best param. lr: {} l2_reg: {}\".format(best_lear, best_regu))\n",
    "\n",
    "## Point predictions\n",
    "T_test_pred, T_train_pred = point_pred(reg, X_test, X_train)\n",
    "\n",
    "## Test model\n",
    "c_test = concordance_index(T_test, T_test_pred)\n",
    "c_train = concordance_index(T_train, T_train_pred)\n",
    "print(c_test)\n",
    "print(\"Model tested\")\n",
    "\n",
    "## Point predictions\n",
    "T_test_pred, T_train_pred = point_pred(reg, X_test, X_train)\n",
    "\n",
    "## Get metrics\n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(T_test,T_test_pred)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(T_train,T_train_pred)    \n",
    "\n",
    "## Save results\n",
    "results['M1'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                  'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                  'R2_test':r2_score(T_test,T_test_pred), \n",
    "                  'R2_train':r2_score(T_train,T_train_pred),\n",
    "                  'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                  'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train,\n",
    "                  'c-train':c_train,'c-test':c_test}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-softball",
   "metadata": {},
   "source": [
    "#### CPH - M5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "internal-carrier",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "C:\\Anaconda\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW BEST!! 0\n",
      "0.11   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW BEST!! 1\n",
      "0.22   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW BEST!! 2\n",
      "0.33   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW BEST!! 3\n",
      "0.44   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW BEST!! 4\n",
      "0.56   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.67   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW BEST!! 6\n",
      "0.78   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW BEST!! 7\n",
      "0.89   "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_split.py:297: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0   Parameter tuning done.\n",
      "Params: learning: 0.1 regularization: 0.1\n",
      "Model fitted\n",
      "Best param. lr: 0.1 l2_reg: 0.1\n",
      "0.6286690297977258\n",
      "Model tested\n"
     ]
    }
   ],
   "source": [
    "results['M5'] = {}\n",
    "\n",
    "# define data\n",
    "X = df[features5_cat + features5_con]\n",
    "X_train, X_test = np.split(X, [int(split * len(df))])\n",
    "T_train, T_test = np.split(df[time_column], [int(split * len(df))])\n",
    "E_train, E_test = np.split(df[event_column], [int(split * len(df))])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train[features5_con] = scaler.fit_transform(X_train[features5_con])\n",
    "X_test[features5_con] = scaler.fit_transform(X_test[features5_con])\n",
    "\n",
    "\n",
    "##############################################################################\n",
    "### Find most optimal parameters for every station\n",
    "best_c = -1\n",
    "best_lear = None\n",
    "best_regu = None\n",
    "best_model = None\n",
    "fails = {}\n",
    "\n",
    "total_it = len(learning_rates)*len(regularization)\n",
    "i=0\n",
    "\n",
    "# loop over parameters\n",
    "for lear in learning_rates:\n",
    "    for regu in regularization:\n",
    "        cv_res = []\n",
    "        try:\n",
    "            kf = KFold(n_splits=3, random_state=42, shuffle=False)\n",
    "            for train_index, test_index in kf.split(X_train):\n",
    "                cph = CoxPHModel()\n",
    "                cph.fit(X_train.loc[train_index], T_train.loc[train_index], E_train.loc[train_index],\n",
    "                        lr=lear, l2_reg = regu, init_method='zeros', max_iter=800, verbose=False)\n",
    "                #point pred\n",
    "                point_predictions = point_pred_single(cph,X_train.loc[test_index])\n",
    "                # c-index\n",
    "                c_temp = concordance_index(T_train.loc[test_index], point_predictions)\n",
    "                cv_res.append(c_temp)\n",
    "                \n",
    "            if np.mean(c_temp) >= best_c:\n",
    "                print(\"NEW BEST!!\", i)\n",
    "                best_lear = lear\n",
    "                best_regu = regu\n",
    "                best_c = np.mean(c_temp)\n",
    "        except:\n",
    "            print(\"FAIL, lr:\", lear, \" l2:\", regu)   \n",
    "        i+=1\n",
    "        print(round(i/total_it,2), \"  \", end='')\n",
    "print(\"Parameter tuning done.\")\n",
    "print(\"Params: learning: {} regularization: {}\".format(best_lear,best_regu))\n",
    "\n",
    "##############################################################################        \n",
    "### Get predictions\n",
    "reg = CoxPHModel()\n",
    "reg.fit(X_train, T_train, E_train, lr=best_lear, l2_reg=best_regu,\n",
    "        init_method='zeros', max_iter=800, verbose=False)\n",
    "print(\"Model fitted\")   \n",
    "print(\"Best param. lr: {} l2_reg: {}\".format(best_lear, best_regu))\n",
    "\n",
    "## Point predictions\n",
    "T_test_pred, T_train_pred = point_pred(reg, X_test, X_train)\n",
    "\n",
    "## Test model\n",
    "c_test = concordance_index(T_test, T_test_pred)\n",
    "c_train = concordance_index(T_train, T_train_pred)\n",
    "print(c_test)\n",
    "print(\"Model tested\")\n",
    "\n",
    "## Get metrics\n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(T_test,T_test_pred)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(T_train,T_train_pred)    \n",
    "\n",
    "## Save results\n",
    "results['M5'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                  'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                  'R2_test':r2_score(T_test,T_test_pred), \n",
    "                  'R2_train':r2_score(T_train,T_train_pred),\n",
    "                  'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                  'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train,\n",
    "                  'c-train':c_train,'c-test':c_test}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-kenya",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "healthy-excuse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------- M1 -------\n",
      "Test:  C-index: 0.63  R2: 0.2 RMSE: 427.0 MAE: 349.0 MAPE: 1920.0\n",
      "Train:  C-index: 0.63  R2: 0.18 RMSE: 456.0 MAE: 356.0 MAPE: 1412.0\n",
      "------- M5 -------\n",
      "Test:  C-index: 0.63  R2: 0.19 RMSE: 431.0 MAE: 350.0 MAPE: 1869.0\n",
      "Train:  C-index: 0.64  R2: 0.19 RMSE: 454.0 MAE: 355.0 MAPE: 1416.0\n"
     ]
    }
   ],
   "source": [
    "for key in results.keys():\n",
    "    r = results[key]\n",
    "    print(\"------- {} -------\".format(key))\n",
    "    print(\"Test:  C-index: {}  R2: {} RMSE: {} MAE: {} MAPE: {}\".format(round(r['c-test'],2),\n",
    "                                                                        round(r['R2_test'],2),\n",
    "                                                                        round(r['RMSE_test'],0),\n",
    "                                                                        round(r['MAE_test'],0),\n",
    "                                                                        round(r['MAPE_test'],0)))\n",
    "    \n",
    "    print(\"Train:  C-index: {}  R2: {} RMSE: {} MAE: {} MAPE: {}\".format(round(r['c-train'],2),\n",
    "                                                                        round(r['R2_train'],2),\n",
    "                                                                        round(r['RMSE_train'],0),\n",
    "                                                                        round(r['MAE_train'],0),\n",
    "                                                                        round(r['MAPE_train'],0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-worst",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
