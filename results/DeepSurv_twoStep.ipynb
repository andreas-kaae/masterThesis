{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "african-pocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import pickle\n",
    "import pickle5\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from pysurvival.models.semi_parametric import NonLinearCoxPHModel\n",
    "from pysurvival.utils.display import display_loss_values\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pysurvival.utils.display import compare_to_actual\n",
    "from pysurvival.utils import save_model, load_model\n",
    "from pysurvival.utils.sklearn_adapter import sklearn_adapter\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import auc, r2_score\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import resample\n",
    "from pysurvival.utils.metrics import concordance_index\n",
    "from lifelines.utils import concordance_index as c_index\n",
    "## block warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "prescribed-method",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>life_time</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_end</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>distance_center_km</th>\n",
       "      <th>weekday_b</th>\n",
       "      <th>charging_ports</th>\n",
       "      <th>lag1</th>\n",
       "      <th>lag2</th>\n",
       "      <th>...</th>\n",
       "      <th>hour_b_22</th>\n",
       "      <th>hour_b_23</th>\n",
       "      <th>Station_Name_BOULDER / N BOULDER REC 1</th>\n",
       "      <th>Station_Name_COMM VITALITY / 1000WALNUT</th>\n",
       "      <th>Station_Name_COMM VITALITY / 1104 SPRUCE1</th>\n",
       "      <th>4Hsplit</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>Station_Name</th>\n",
       "      <th>weekday_b_name</th>\n",
       "      <th>tod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3734</th>\n",
       "      <td>118.5</td>\n",
       "      <td>2018-01-05 14:25:00</td>\n",
       "      <td>2018-01-05 16:23:30</td>\n",
       "      <td>40.000148</td>\n",
       "      <td>-105.282437</td>\n",
       "      <td>2.096847</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1271.5</td>\n",
       "      <td>135.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>BOULDER / BASELINE ST1</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Midday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3735</th>\n",
       "      <td>886.5</td>\n",
       "      <td>2018-01-05 17:02:00</td>\n",
       "      <td>2018-01-06 07:48:30</td>\n",
       "      <td>40.000148</td>\n",
       "      <td>-105.282437</td>\n",
       "      <td>2.096847</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>118.5</td>\n",
       "      <td>1271.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>BOULDER / BASELINE ST1</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Afternoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3736</th>\n",
       "      <td>326.5</td>\n",
       "      <td>2018-01-06 09:28:00</td>\n",
       "      <td>2018-01-06 14:54:30</td>\n",
       "      <td>40.000148</td>\n",
       "      <td>-105.282437</td>\n",
       "      <td>2.096847</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>886.5</td>\n",
       "      <td>118.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>BOULDER / BASELINE ST1</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      life_time      datetime_start        datetime_end   latitude  \\\n",
       "3734      118.5 2018-01-05 14:25:00 2018-01-05 16:23:30  40.000148   \n",
       "3735      886.5 2018-01-05 17:02:00 2018-01-06 07:48:30  40.000148   \n",
       "3736      326.5 2018-01-06 09:28:00 2018-01-06 14:54:30  40.000148   \n",
       "\n",
       "       longitude  distance_center_km  weekday_b  charging_ports    lag1  \\\n",
       "3734 -105.282437            2.096847          4               2  1271.5   \n",
       "3735 -105.282437            2.096847          4               2   118.5   \n",
       "3736 -105.282437            2.096847          5               2   886.5   \n",
       "\n",
       "        lag2  ...  hour_b_22  hour_b_23  \\\n",
       "3734   135.5  ...          0          0   \n",
       "3735  1271.5  ...          0          0   \n",
       "3736   118.5  ...          0          0   \n",
       "\n",
       "      Station_Name_BOULDER / N BOULDER REC 1  \\\n",
       "3734                                       0   \n",
       "3735                                       0   \n",
       "3736                                       0   \n",
       "\n",
       "      Station_Name_COMM VITALITY / 1000WALNUT  \\\n",
       "3734                                        0   \n",
       "3735                                        0   \n",
       "3736                                        0   \n",
       "\n",
       "      Station_Name_COMM VITALITY / 1104 SPRUCE1  4Hsplit  y_pred  \\\n",
       "3734                                          0        0       1   \n",
       "3735                                          0        1       1   \n",
       "3736                                          0        1       0   \n",
       "\n",
       "                Station_Name  weekday_b_name        tod  \n",
       "3734  BOULDER / BASELINE ST1          Friday     Midday  \n",
       "3735  BOULDER / BASELINE ST1          Friday  Afternoon  \n",
       "3736  BOULDER / BASELINE ST1        Saturday    Morning  \n",
       "\n",
       "[3 rows x 102 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../data/ut_V6_classification-4H.pkl\", \"rb\") as fh:\n",
    "    df = pickle5.load(fh)\n",
    "    \n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scenic-mills",
   "metadata": {},
   "source": [
    "## Modeling features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "straight-reform",
   "metadata": {},
   "source": [
    "To make coding easier the names of the models are changed:\n",
    "- M1: Baseline\n",
    "- M5: Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "civic-classroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['event'] = np.ones(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dressed-vegetation",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_column = 'life_time'\n",
    "event_column = 'event'\n",
    "\n",
    "## M1\n",
    "features1 = ['weekday_b_name_Monday', 'weekday_b_name_Saturday',\n",
    "             'weekday_b_name_Sunday', 'weekday_b_name_Thursday',\n",
    "             'weekday_b_name_Tuesday', 'weekday_b_name_Wednesday', 'tod_Evening', 'tod_Midday', 'tod_Morning',\n",
    "       'Station_Name_BOULDER / N BOULDER REC 1',\n",
    "       'Station_Name_COMM VITALITY / 1000WALNUT',\n",
    "       'Station_Name_COMM VITALITY / 1104 SPRUCE1'] # dow + tod\n",
    "\n",
    "## M5\n",
    "features5_cat = ['weekday_b_name_Monday', 'weekday_b_name_Saturday',\n",
    "             'weekday_b_name_Sunday', 'weekday_b_name_Thursday',\n",
    "             'weekday_b_name_Tuesday', 'weekday_b_name_Wednesday','tod_Evening', 'tod_Midday', 'tod_Morning',\n",
    "       'Station_Name_BOULDER / N BOULDER REC 1',\n",
    "       'Station_Name_COMM VITALITY / 1000WALNUT',\n",
    "       'Station_Name_COMM VITALITY / 1104 SPRUCE1']\n",
    "features5_con = ['lag1', 'lag2', 'lag3','near_charge_time_4H', 'near_charge_energy_4H',\n",
    "                 'charge_time_4H', 'charge_energy_4H','service', 'entertainment', 'food', \n",
    "                 'childcare', 'medical', 'education', 'waste-management']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "front-atmosphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data split\n",
    "split = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "popular-netscape",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (4088, 103)\n",
      "Testing shape: (1022, 103)\n"
     ]
    }
   ],
   "source": [
    "train, test = np.split(df, [int(split * len(df))])\n",
    "print(\"Training shape:\",train.shape)\n",
    "print(\"Testing shape:\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "psychological-nothing",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainS = train[train['y_pred'] == 0]\n",
    "trainL = train[train['y_pred'] == 1]\n",
    "\n",
    "testS = test[test['y_pred'] == 0]\n",
    "testL = test[test['y_pred'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "signal-transsexual",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHORT: Train: 2433 Test: 629\n",
      "LONG: Train: 1655 Test: 393\n"
     ]
    }
   ],
   "source": [
    "print(\"SHORT: Train: {} Test: {}\".format(trainS.shape[0], testS.shape[0]))\n",
    "print(\"LONG: Train: {} Test: {}\".format(trainL.shape[0], testL.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fatty-transformation",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get X \n",
    "# Baseline\n",
    "X1_S = trainS[features1]\n",
    "X1_L = trainL[features1]\n",
    "\n",
    "## Full\n",
    "# Short\n",
    "X5_S = trainS[features5_cat+features5_con]\n",
    "scaler = StandardScaler()\n",
    "X5_S[features5_con] = scaler.fit_transform(X5_S[features5_con])\n",
    "X5_S_test = testS[features5_cat+features5_con]\n",
    "X5_S_test[features5_con] = scaler.transform(X5_S_test[features5_con])\n",
    "# Full\n",
    "X5_L = trainL[features5_cat+features5_con]\n",
    "scaler = StandardScaler()\n",
    "X5_L[features5_con] = scaler.fit_transform(X5_L[features5_con])\n",
    "X5_L_test = testL[features5_cat+features5_con]\n",
    "X5_L_test[features5_con] = scaler.transform(X5_L_test[features5_con])\n",
    "\n",
    "## Get E -train\n",
    "E_S = trainS[event_column]\n",
    "E_L = trainL[event_column]\n",
    "\n",
    "## Get T - train\n",
    "T_S = trainS['life_time']\n",
    "T_L = trainL['life_time']\n",
    "\n",
    "## Get E -Test\n",
    "E_S_test = testS[event_column]\n",
    "E_L_test = testL[event_column]\n",
    "\n",
    "## Get T - Test\n",
    "T_S_test = testS['life_time']\n",
    "T_L_test = testL['life_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aggregate-innocent",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define grid for RandomizedsearchCV\n",
    "## One layers\n",
    "struc10 = [{'activation': 'ReLU', 'num_units': 16}]\n",
    "struc11 = [{'activation': 'ReLU', 'num_units': 32}]\n",
    "struc12 = [{'activation': 'ReLU', 'num_units': 64}]\n",
    "struc13 = [{'activation': 'ReLU', 'num_units': 128}]\n",
    "struc14 = [{'activation': 'ReLU', 'num_units': 264}]\n",
    "\n",
    "## Two layers\n",
    "struc20 = [{'activation': 'ReLU', 'num_units': 16},{'activation': 'ReLU', 'num_units': 16}]\n",
    "struc21 = [{'activation': 'ReLU', 'num_units': 32},{'activation': 'ReLU', 'num_units': 32}]\n",
    "struc22 = [{'activation': 'ReLU', 'num_units': 64},{'activation': 'ReLU', 'num_units': 64}]\n",
    "struc23 = [{'activation': 'ReLU', 'num_units': 128},{'activation': 'ReLU', 'num_units': 128}]\n",
    "struc24 = [{'activation': 'ReLU', 'num_units': 264},{'activation': 'ReLU', 'num_units': 264}]\n",
    "\n",
    "## Three layers\n",
    "struc30 = [{'activation': 'ReLU', 'num_units': 16},{'activation': 'ReLU', 'num_units': 16},\n",
    "           {'activation': 'ReLU', 'num_units': 16}]\n",
    "struc31 = [{'activation': 'ReLU', 'num_units': 32},{'activation': 'ReLU', 'num_units': 32},\n",
    "           {'activation': 'ReLU', 'num_units': 32}]\n",
    "struc32 = [{'activation': 'ReLU', 'num_units': 64},{'activation': 'ReLU', 'num_units': 64}, \n",
    "           {'activation': 'ReLU', 'num_units': 64}]\n",
    "struc33 = [{'activation': 'ReLU', 'num_units': 128},{'activation': 'ReLU', 'num_units': 128},\n",
    "           {'activation': 'ReLU', 'num_units': 128}]\n",
    "struc34 = [{'activation': 'ReLU', 'num_units': 264},{'activation': 'ReLU', 'num_units': 264},\n",
    "           {'activation': 'ReLU', 'num_units': 264}]\n",
    "\n",
    "## Four layers\n",
    "struc40 = [{'activation': 'ReLU', 'num_units': 16},{'activation': 'ReLU', 'num_units': 16},\n",
    "           {'activation': 'ReLU', 'num_units': 16},{'activation': 'ReLU', 'num_units': 16}]\n",
    "struc41 = [{'activation': 'ReLU', 'num_units': 32},{'activation': 'ReLU', 'num_units': 32},\n",
    "           {'activation': 'ReLU', 'num_units': 32},{'activation': 'ReLU', 'num_units': 32}]\n",
    "struc42 = [{'activation': 'ReLU', 'num_units': 64},{'activation': 'ReLU', 'num_units': 64}, \n",
    "           {'activation': 'ReLU', 'num_units': 64},{'activation': 'ReLU', 'num_units': 64}]\n",
    "struc43 = [{'activation': 'ReLU', 'num_units': 128},{'activation': 'ReLU', 'num_units': 128},\n",
    "           {'activation': 'ReLU', 'num_units': 128},{'activation': 'ReLU', 'num_units': 128}]\n",
    "struc44 = [{'activation': 'ReLU', 'num_units': 264},{'activation': 'ReLU', 'num_units': 264},\n",
    "           {'activation': 'ReLU', 'num_units': 264},{'activation': 'ReLU', 'num_units': 264}]\n",
    "\n",
    "## define grid\n",
    "grid = {'lr':[0.0001,0.001,0.01,0.1], 'l2_reg':[0.0001,0.001,0.01,1,10],\n",
    "        'structure':[struc10,struc11,struc12,struc13,struc14,struc20,struc21,struc22,struc23,struc24,\n",
    "                     struc30,struc31,struc32,struc33,struc34,struc40,struc41,struc42,struc43,struc44],\n",
    "        'dropout':[0.1,0.25,0.5], 'num_epochs':[10,100,500,1000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "multiple-winner",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "purple-death",
   "metadata": {},
   "source": [
    "### Find hyper parameters\n",
    "Short:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "natural-elder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters, baseline - SHORT {'structure': [{'activation': 'ReLU', 'num_units': 32}], 'num_epochs': 10, 'lr': 0.1, 'l2_reg': 10, 'dropout': 0.25}\n",
      "Parameters, baseline - LONG {'structure': [{'activation': 'ReLU', 'num_units': 128}, {'activation': 'ReLU', 'num_units': 128}], 'num_epochs': 100, 'lr': 0.01, 'l2_reg': 0.01, 'dropout': 0.1}\n",
      "Parameters, full - SHORT {'structure': [{'activation': 'ReLU', 'num_units': 16}], 'num_epochs': 1000, 'lr': 0.0001, 'l2_reg': 1, 'dropout': 0.1}\n",
      "Parameters, full - LONG {'structure': [{'activation': 'ReLU', 'num_units': 128}, {'activation': 'ReLU', 'num_units': 128}], 'num_epochs': 100, 'lr': 0.01, 'l2_reg': 0.01, 'dropout': 0.1}\n"
     ]
    }
   ],
   "source": [
    "########### M1\n",
    "#### SHORT\n",
    "## sklearn adapter\n",
    "dsSklearn = sklearn_adapter(NonLinearCoxPHModel, time_col=time_column, event_col=event_column,\n",
    "                          predict_method=\"predict_survival\", scoring_method=concordance_index)\n",
    "dsSkl = dsSklearn()\n",
    "reg = RandomizedSearchCV(dsSkl, grid, random_state=42, n_iter=50, cv=5) # if n_iter = 100 it will train 100 models.\n",
    "reg.fit(X1_S,y_S, verbose=False, batch_normalization=False)\n",
    "paramS1 = reg.best_params_\n",
    "print(\"Parameters, baseline - SHORT\",paramS1)\n",
    "\n",
    "#### LONG\n",
    "## sklearn adapter\n",
    "dsSklearn = sklearn_adapter(NonLinearCoxPHModel, time_col=time_column, event_col=event_column,\n",
    "                          predict_method=\"predict_survival\", scoring_method=concordance_index)\n",
    "dsSkl = dsSklearn()\n",
    "reg = RandomizedSearchCV(dsSkl, grid, random_state=42, n_iter=50, cv=5) # if n_iter = 100 it will train 100 models.\n",
    "reg.fit(X1_L,y_L, verbose=False, batch_normalization=False)\n",
    "paramL1 = reg.best_params_\n",
    "print(\"Parameters, baseline - LONG\",paramL1)\n",
    "\n",
    "########### M5\n",
    "#### SHORT\n",
    "## sklearn adapter\n",
    "dsSklearn = sklearn_adapter(NonLinearCoxPHModel, time_col=time_column, event_col=event_column,\n",
    "                          predict_method=\"predict_survival\", scoring_method=concordance_index)\n",
    "dsSkl = dsSklearn()\n",
    "reg = RandomizedSearchCV(dsSkl, grid, random_state=42, n_iter=50, cv=5) # if n_iter = 100 it will train 100 models.\n",
    "reg.fit(X5_S,y_S, verbose=False, batch_normalization=False)\n",
    "paramS5 = reg.best_params_\n",
    "print(\"Parameters, full - SHORT\",paramS5)\n",
    "\n",
    "#### LONG\n",
    "## sklearn adapter\n",
    "dsSklearn = sklearn_adapter(NonLinearCoxPHModel, time_col=time_column, event_col=event_column,\n",
    "                          predict_method=\"predict_survival\", scoring_method=concordance_index)\n",
    "dsSkl = dsSklearn()\n",
    "reg = RandomizedSearchCV(dsSkl, grid, random_state=42, n_iter=50, cv=5) # if n_iter = 100 it will train 100 models.\n",
    "reg.fit(X5_L,y_L, verbose=False, batch_normalization=False)\n",
    "paramL5 = reg.best_params_\n",
    "print(\"Parameters, full - LONG\",paramL5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elegant-equality",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To test model\n",
    "def test_model(y_test, y_pred):\n",
    "    MAE = metrics.mean_absolute_error(y_test, y_pred)\n",
    "    MSE = metrics.mean_squared_error(y_test, y_pred)\n",
    "    RMSE = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "    MAPE = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    NRMSE = RMSE/np.mean(y_test)\n",
    "    return MAE, RMSE, MSE, MAPE, NRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-morning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stock-remains",
   "metadata": {},
   "source": [
    "#### DeepSurv - Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "purple-secretary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHORT\n",
      "Model tested\n",
      "LONG\n",
      "Model tested\n"
     ]
    }
   ],
   "source": [
    "#########################################################\n",
    "#################### SEPERATE RESULTS ###################\n",
    "\n",
    "results['M1'] = {}\n",
    "results['M1']['S'] = {}\n",
    "results['M1']['L'] = {}\n",
    "results['M1']['Com'] = {}\n",
    "\n",
    "################ Fit models ################\n",
    "#\n",
    "####################### short #######################\n",
    "print(\"SHORT\")\n",
    "## Fit model\n",
    "reg = NonLinearCoxPHModel(structure=paramS1['structure'])\n",
    "reg.fit(X1_S, T_S, E_S, lr=paramS1['lr'], l2_reg=paramS1['l2_reg'], \n",
    "        batch_normalization=False, verbose=False, num_epochs=paramS1['num_epochs'],\n",
    "        dropout=paramS1['dropout'])\n",
    "\n",
    "## Point predictions\n",
    "T_test_pred_S, T_train_pred_S = point_pred(reg, X1_S_test, X1_S)\n",
    "\n",
    "## Test model\n",
    "c_test = c_index(T_S_test, T_test_pred_S)\n",
    "c_train = c_index(T_S, T_train_pred_S)\n",
    "print(\"Model tested\")\n",
    "\n",
    "## Get metrics\n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(T_S_test,T_test_pred_S)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(T_S,T_train_pred_S)\n",
    "\n",
    "## Save results\n",
    "results['M1']['S'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                  'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                  'R2_test':r2_score(T_S_test,T_test_pred_S), \n",
    "                  'R2_train':r2_score(T_S,T_train_pred_S),\n",
    "                  'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                  'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train,\n",
    "                  'c-train':c_train,'c-test':c_test}\n",
    "\n",
    "####################### long #######################\n",
    "print(\"LONG\")\n",
    "\n",
    "## Fit model\n",
    "reg = NonLinearCoxPHModel(structure=paramL1['structure'])\n",
    "reg.fit(X1_L, T_L, E_L, lr=paramL1['lr'], l2_reg=paramL1['l2_reg'], \n",
    "        batch_normalization=False, verbose=False, num_epochs=paramL1['num_epochs'],\n",
    "        dropout=paramL1['dropout'])\n",
    "\n",
    "## Point predictions\n",
    "T_test_pred_L, T_train_pred_L = point_pred(reg, X1_L_test, X1_L)\n",
    "\n",
    "## Test model\n",
    "c_test = c_index(T_L_test, T_test_pred_L)\n",
    "c_train = c_index(T_L, T_train_pred_L)\n",
    "print(\"Model tested\")\n",
    "\n",
    "## Get metrics\n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(T_L_test,T_test_pred_L)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(T_L,T_train_pred_L)\n",
    "\n",
    "## Save results\n",
    "results['M1']['L'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                  'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                  'R2_test':r2_score(T_L_test,T_test_pred_L), \n",
    "                  'R2_train':r2_score(T_L,T_train_pred_L),\n",
    "                  'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                  'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train,\n",
    "                  'c-train':c_train,'c-test':c_test}\n",
    "\n",
    "###############################################################\n",
    "############ COMBINED ###################\n",
    "\n",
    "T_com_real_test1 = pd.concat([T_S_test, T_L_test])\n",
    "T_test_pred_S.extend(T_test_pred_L)\n",
    "T_com_pred_test1 = T_test_pred_S\n",
    "\n",
    "T_com_real_train = pd.concat([T_S, T_L])\n",
    "T_train_pred_S.extend(T_train_pred_L)\n",
    "T_com_pred_train = T_train_pred_S\n",
    "\n",
    "## Get metrics\n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(T_com_real_test1, T_com_pred_test1)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(T_com_real_train, T_com_pred_train) \n",
    "\n",
    "## C-index\n",
    "c_test = c_index(T_com_real_test1, T_com_pred_test1)\n",
    "c_train = c_index(T_com_real_train, T_com_pred_train)\n",
    "\n",
    "## Save results\n",
    "results['M1']['Com'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                      'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                      'R2_test':r2_score(T_com_real_test1,T_com_pred_test1), \n",
    "                      'R2_train':r2_score(T_com_real_train,T_com_pred_train),\n",
    "                      'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                      'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train,\n",
    "                      'c-train':c_train,'c-test':c_test}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-genome",
   "metadata": {},
   "source": [
    "#### DeepSurv - Model 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "nervous-thousand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHORT\n",
      "Model tested\n",
      "LONG\n",
      "Model tested\n"
     ]
    }
   ],
   "source": [
    "#########################################################\n",
    "#################### SEPERATE RESULTS ###################\n",
    "\n",
    "results['M5'] = {}\n",
    "results['M5']['S'] = {}\n",
    "results['M5']['L'] = {}\n",
    "results['M5']['Com'] = {}\n",
    "\n",
    "################ Fit models ################\n",
    "#\n",
    "####################### short #######################\n",
    "print(\"SHORT\")\n",
    "## Fit model\n",
    "reg = NonLinearCoxPHModel(structure=paramS5['structure'])\n",
    "reg.fit(X5_S, T_S, E_S, lr=paramS5['lr'], l2_reg=paramS5['l2_reg'], \n",
    "        batch_normalization=False, verbose=False, num_epochs=paramS5['num_epochs'],\n",
    "        dropout=paramS5['dropout'])\n",
    "\n",
    "## Point predictions\n",
    "T_test_pred_S, T_train_pred_S = point_pred(reg, X5_S_test, X5_S)\n",
    "\n",
    "## Test model\n",
    "c_test = c_index(T_S_test, T_test_pred_S)\n",
    "c_train = c_index(T_S, T_train_pred_S)\n",
    "print(\"Model tested\")\n",
    "\n",
    "## Get metrics\n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(T_S_test,T_test_pred_S)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(T_S,T_train_pred_S)\n",
    "\n",
    "## Save results\n",
    "results['M5']['S'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                  'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                  'R2_test':r2_score(T_S_test,T_test_pred_S), \n",
    "                  'R2_train':r2_score(T_S,T_train_pred_S),\n",
    "                  'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                  'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train,\n",
    "                  'c-train':c_train,'c-test':c_test}\n",
    "\n",
    "####################### long #######################\n",
    "print(\"LONG\")\n",
    "\n",
    "## Fit model\n",
    "reg = NonLinearCoxPHModel(structure=paramL5['structure'])\n",
    "reg.fit(X5_L, T_L, E_L, lr=paramL5['lr'], l2_reg=paramL5['l2_reg'], \n",
    "        batch_normalization=False, verbose=False, num_epochs=paramL5['num_epochs'],\n",
    "        dropout=paramL1['dropout'])\n",
    "\n",
    "## Point predictions\n",
    "T_test_pred_L, T_train_pred_L = point_pred(reg, X5_L_test, X5_L)\n",
    "\n",
    "## Test model\n",
    "c_test = c_index(T_L_test, T_test_pred_L)\n",
    "c_train = c_index(T_L, T_train_pred_L)\n",
    "print(\"Model tested\")\n",
    "\n",
    "## Get metrics\n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(T_L_test,T_test_pred_L)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(T_L,T_train_pred_L)\n",
    "\n",
    "## Save results\n",
    "results['M5']['L'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                  'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                  'R2_test':r2_score(T_L_test,T_test_pred_L), \n",
    "                  'R2_train':r2_score(T_L,T_train_pred_L),\n",
    "                  'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                  'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train,\n",
    "                  'c-train':c_train,'c-test':c_test}\n",
    "\n",
    "###############################################################\n",
    "############ COMBINED ###################\n",
    "\n",
    "T_com_real_test5 = pd.concat([T_S_test, T_L_test])\n",
    "T_test_pred_S.extend(T_test_pred_L)\n",
    "T_com_pred_test5 = T_test_pred_S\n",
    "\n",
    "T_com_real_train = pd.concat([T_S, T_L])\n",
    "T_train_pred_S.extend(T_train_pred_L)\n",
    "T_com_pred_train = T_train_pred_S\n",
    "\n",
    "## Get metrics\n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(T_com_real_test5, T_com_pred_test5)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(T_com_real_train, T_com_pred_train) \n",
    "\n",
    "## C-index\n",
    "c_test = c_index(T_com_real_test5, T_com_pred_test5)\n",
    "c_train = c_index(T_com_real_train, T_com_pred_train)\n",
    "\n",
    "## Save results\n",
    "results['M5']['Com'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                      'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                      'R2_test':r2_score(T_com_real_test5,T_com_pred_test5), \n",
    "                      'R2_train':r2_score(T_com_real_train,T_com_pred_train),\n",
    "                      'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                      'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train,\n",
    "                      'c-train':c_train,'c-test':c_test}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "arabic-spray",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save results dictionary\n",
    "with open(\"results/DeepSurv_predictions_twostage.pickle\", 'wb') as handle:\n",
    "    pickle.dump(combined_pred, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mineral-kenya",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "amazing-worst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHORT\n",
      "DeepSurv M1: R2: -0.02 RMSE: 403.0 C-idx: 0.52 MAE: 317.0 MAPE: 2047.0 NRMSE: 1.43\n",
      "DeepSurv M5: R2: -0.05 RMSE: 409.0 C-idx: 0.53 MAE: 330.0 MAPE: 2252.0 NRMSE: 1.45\n"
     ]
    }
   ],
   "source": [
    "models = ['M1', 'M5']\n",
    "\n",
    "print(\"SHORT\")\n",
    "for mo in models:\n",
    "    r = results[mo]['S']   \n",
    "    RMSE = r['RMSE_test']\n",
    "    R2 = r['R2_test']\n",
    "    MAE = r['MAE_test']\n",
    "    MAPE = r['MAPE_test']\n",
    "    NRMSE = r['NRMSE_test']\n",
    "    C_idx = r['c-test']\n",
    "\n",
    "    print(\"DeepSurv {}: R2: {} RMSE: {} C-idx: {} MAE: {} MAPE: {} NRMSE: {}\".format(mo,\n",
    "                                                                          round(R2,2),\n",
    "                                                                          round(RMSE,0),\n",
    "                                                                          round(C_idx,2),\n",
    "                                                                          round(MAE,0),\n",
    "                                                                          round(MAPE,0),\n",
    "                                                                          round(NRMSE,2))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "split-recipient",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LONG\n",
      "DeepSurv M1: R2: -0.02 RMSE: 458.0 C-idx: 0.6 MAE: 343.0 MAPE: 1340.0 NRMSE: 0.61\n",
      "DeepSurv M5: R2: -0.17 RMSE: 489.0 C-idx: 0.6 MAE: 365.0 MAPE: 1469.0 NRMSE: 0.65\n"
     ]
    }
   ],
   "source": [
    "models = ['M1', 'M5']\n",
    "\n",
    "print(\"LONG\")\n",
    "for mo in models:\n",
    "    r = results[mo]['L']   \n",
    "    RMSE = r['RMSE_test']\n",
    "    R2 = r['R2_test']\n",
    "    MAE = r['MAE_test']\n",
    "    MAPE = r['MAPE_test']\n",
    "    NRMSE = r['NRMSE_test']\n",
    "    C_idx = r['c-test']\n",
    "\n",
    "    print(\"DeepSurv {}: R2: {} RMSE: {} C-idx: {} MAE: {} MAPE: {} NRMSE: {}\".format(mo,\n",
    "                                                                          round(R2,2),\n",
    "                                                                          round(RMSE,0),\n",
    "                                                                          round(C_idx,2),\n",
    "                                                                          round(MAE,0),\n",
    "                                                                          round(MAPE,0),\n",
    "                                                                          round(NRMSE,2))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "convenient-kinase",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined\n",
      "DeepSurv M1: R2: 0.21 RMSE: 425.0 C-idx: 0.64 MAE: 327.0 MAPE: 1775.0 NRMSE: 0.92\n",
      "DeepSurv M5: R2: 0.15 RMSE: 441.0 C-idx: 0.63 MAE: 344.0 MAPE: 1951.0 NRMSE: 0.96\n"
     ]
    }
   ],
   "source": [
    "models = ['M1', 'M5']\n",
    "\n",
    "print(\"Combined\")\n",
    "for mo in models:\n",
    "    r = results[mo]['Com']   \n",
    "    RMSE = r['RMSE_test']\n",
    "    R2 = r['R2_test']\n",
    "    MAE = r['MAE_test']\n",
    "    MAPE = r['MAPE_test']\n",
    "    NRMSE = r['NRMSE_test']\n",
    "    C_idx = r['c-test']\n",
    "\n",
    "    print(\"DeepSurv {}: R2: {} RMSE: {} C-idx: {} MAE: {} MAPE: {} NRMSE: {}\".format(mo,\n",
    "                                                                          round(R2,2),\n",
    "                                                                          round(RMSE,0),\n",
    "                                                                          round(C_idx,2),\n",
    "                                                                          round(MAE,0),\n",
    "                                                                          round(MAPE,0),\n",
    "                                                                          round(NRMSE,2))) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
