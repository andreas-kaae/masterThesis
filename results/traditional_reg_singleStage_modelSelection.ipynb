{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "linear-sunrise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import pickle\n",
    "import pickle5\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import r2_score   \n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import folium\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "## block warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "straight-termination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>life_time</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_end</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>distance_center_km</th>\n",
       "      <th>Station_Name</th>\n",
       "      <th>weekday_b</th>\n",
       "      <th>weekday_b_name</th>\n",
       "      <th>hour_b</th>\n",
       "      <th>...</th>\n",
       "      <th>near_inactivity_6H</th>\n",
       "      <th>near_charge_events_6H</th>\n",
       "      <th>service</th>\n",
       "      <th>entertainment</th>\n",
       "      <th>food</th>\n",
       "      <th>childcare</th>\n",
       "      <th>medical</th>\n",
       "      <th>education</th>\n",
       "      <th>parking</th>\n",
       "      <th>waste-management</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>928.5</td>\n",
       "      <td>2018-01-31 19:51:00</td>\n",
       "      <td>2018-02-01 11:19:30</td>\n",
       "      <td>40.018482</td>\n",
       "      <td>-105.281066</td>\n",
       "      <td>0.152203</td>\n",
       "      <td>COMM VITALITY / 1104 SPRUCE1</td>\n",
       "      <td>2</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>19</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.057343</td>\n",
       "      <td>0.109796</td>\n",
       "      <td>0.073649</td>\n",
       "      <td>3.517121</td>\n",
       "      <td>0.466518</td>\n",
       "      <td>0.631771</td>\n",
       "      <td>0.021832</td>\n",
       "      <td>1.145959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>363.5</td>\n",
       "      <td>2018-02-01 14:03:00</td>\n",
       "      <td>2018-02-01 20:06:30</td>\n",
       "      <td>40.018482</td>\n",
       "      <td>-105.281066</td>\n",
       "      <td>0.152203</td>\n",
       "      <td>COMM VITALITY / 1104 SPRUCE1</td>\n",
       "      <td>3</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>14</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.057343</td>\n",
       "      <td>0.109796</td>\n",
       "      <td>0.073649</td>\n",
       "      <td>3.517121</td>\n",
       "      <td>0.466518</td>\n",
       "      <td>0.631771</td>\n",
       "      <td>0.021832</td>\n",
       "      <td>1.145959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6828.5</td>\n",
       "      <td>2018-02-01 21:15:00</td>\n",
       "      <td>2018-02-06 15:03:30</td>\n",
       "      <td>40.018482</td>\n",
       "      <td>-105.281066</td>\n",
       "      <td>0.152203</td>\n",
       "      <td>COMM VITALITY / 1104 SPRUCE1</td>\n",
       "      <td>3</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.057343</td>\n",
       "      <td>0.109796</td>\n",
       "      <td>0.073649</td>\n",
       "      <td>3.517121</td>\n",
       "      <td>0.466518</td>\n",
       "      <td>0.631771</td>\n",
       "      <td>0.021832</td>\n",
       "      <td>1.145959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5871.5</td>\n",
       "      <td>2018-02-06 15:27:00</td>\n",
       "      <td>2018-02-10 17:18:30</td>\n",
       "      <td>40.018482</td>\n",
       "      <td>-105.281066</td>\n",
       "      <td>0.152203</td>\n",
       "      <td>COMM VITALITY / 1104 SPRUCE1</td>\n",
       "      <td>1</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>15</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.057343</td>\n",
       "      <td>0.109796</td>\n",
       "      <td>0.073649</td>\n",
       "      <td>3.517121</td>\n",
       "      <td>0.466518</td>\n",
       "      <td>0.631771</td>\n",
       "      <td>0.021832</td>\n",
       "      <td>1.145959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1454.5</td>\n",
       "      <td>2018-02-10 18:26:00</td>\n",
       "      <td>2018-02-11 18:40:30</td>\n",
       "      <td>40.018482</td>\n",
       "      <td>-105.281066</td>\n",
       "      <td>0.152203</td>\n",
       "      <td>COMM VITALITY / 1104 SPRUCE1</td>\n",
       "      <td>5</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.057343</td>\n",
       "      <td>0.109796</td>\n",
       "      <td>0.073649</td>\n",
       "      <td>3.517121</td>\n",
       "      <td>0.466518</td>\n",
       "      <td>0.631771</td>\n",
       "      <td>0.021832</td>\n",
       "      <td>1.145959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   life_time      datetime_start        datetime_end   latitude   longitude  \\\n",
       "0      928.5 2018-01-31 19:51:00 2018-02-01 11:19:30  40.018482 -105.281066   \n",
       "1      363.5 2018-02-01 14:03:00 2018-02-01 20:06:30  40.018482 -105.281066   \n",
       "2     6828.5 2018-02-01 21:15:00 2018-02-06 15:03:30  40.018482 -105.281066   \n",
       "3     5871.5 2018-02-06 15:27:00 2018-02-10 17:18:30  40.018482 -105.281066   \n",
       "4     1454.5 2018-02-10 18:26:00 2018-02-11 18:40:30  40.018482 -105.281066   \n",
       "\n",
       "   distance_center_km                  Station_Name  weekday_b weekday_b_name  \\\n",
       "0            0.152203  COMM VITALITY / 1104 SPRUCE1          2      Wednesday   \n",
       "1            0.152203  COMM VITALITY / 1104 SPRUCE1          3       Thursday   \n",
       "2            0.152203  COMM VITALITY / 1104 SPRUCE1          3       Thursday   \n",
       "3            0.152203  COMM VITALITY / 1104 SPRUCE1          1        Tuesday   \n",
       "4            0.152203  COMM VITALITY / 1104 SPRUCE1          5       Saturday   \n",
       "\n",
       "   hour_b  ...  near_inactivity_6H  near_charge_events_6H   service  \\\n",
       "0      19  ...                 0.0                      0  0.057343   \n",
       "1      14  ...                 0.0                      0  0.057343   \n",
       "2      21  ...                 0.0                      0  0.057343   \n",
       "3      15  ...                 0.0                      0  0.057343   \n",
       "4      18  ...                 0.0                      0  0.057343   \n",
       "\n",
       "   entertainment      food  childcare   medical  education   parking  \\\n",
       "0       0.109796  0.073649   3.517121  0.466518   0.631771  0.021832   \n",
       "1       0.109796  0.073649   3.517121  0.466518   0.631771  0.021832   \n",
       "2       0.109796  0.073649   3.517121  0.466518   0.631771  0.021832   \n",
       "3       0.109796  0.073649   3.517121  0.466518   0.631771  0.021832   \n",
       "4       0.109796  0.073649   3.517121  0.466518   0.631771  0.021832   \n",
       "\n",
       "   waste-management  \n",
       "0          1.145959  \n",
       "1          1.145959  \n",
       "2          1.145959  \n",
       "3          1.145959  \n",
       "4          1.145959  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../data/ut_poiV6.pkl\", \"rb\") as fh:\n",
    "    df = pickle5.load(fh)\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "unlikely-radius",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12711, 71)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continuous-mistress",
   "metadata": {},
   "source": [
    "### Remove events\n",
    "The features we have constructed means that we automatically will loose some data. To use the lagged feature we need to remove the 3 first observations. In the code below we check if the sum of the 3 first life times are above 3 hours. If they are then we do not need to remove additinal variables due to the 3 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "allied-biodiversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = df['Station_Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "declared-zimbabwe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The station has the lagged\n",
      "BOULDER / REC CENTER\n",
      "The station has the lagged\n",
      "BOULDER / ATRIUM ST1\n",
      "The station has the lagged\n",
      "BOULDER / ALPINE ST1\n",
      "The station has the lagged\n",
      "COMM VITALITY / 1400 WALNUT1\n",
      "The station has the lagged\n",
      "BOULDER / FACILITIES ST1\n",
      "The station has the lagged\n",
      "COMM VITALITY / 1500PEARL\n",
      "The station has the lagged\n",
      "BOULDER / JUNCTION ST1\n",
      "The station has the lagged\n",
      "COMM VITALITY / BOULDER JCTN\n",
      "The station has the lagged\n",
      "COMM VITALITY / 1100WALNUT1\n",
      "The station has the lagged\n",
      "BOULDER / BOULDER PARK\n",
      "The station has the lagged\n",
      "COMM VITALITY / 2200 BROADWAY1\n",
      "The station has the lagged\n",
      "BOULDER / EAST REC\n",
      "The station has the lagged\n",
      "BOULDERJUNCTION / JUNCTION ST1\n"
     ]
    }
   ],
   "source": [
    "for name in names:\n",
    "    temp = df[df['Station_Name'] == name]\n",
    "    rows = temp[temp['lag3'].isna()]\n",
    "    if rows.life_time.sum() < 3*60:\n",
    "        print(\"The station has the lagged\")\n",
    "        print(name)\n",
    "\n",
    "# remove rows\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "extreme-arrangement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12699, 71)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "upper-blend",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Limit to only top 10 stations\n",
    "temp = df.groupby(['Station_Name']).count().latitude # group the data for each station\n",
    "names10 = temp.sort_values(ascending=False)[0:10]\n",
    "names10 = names10.index.values\n",
    "\n",
    "df = df[df['Station_Name'].isin(names10)]\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "polar-green",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10762, 71)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-pound",
   "metadata": {},
   "source": [
    "## Remove outliers\n",
    "Use boxplot outlier definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cardiovascular-bolivia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMM VITALITY / 1104 SPRUCE1: 57 (4.4 %)\n",
      "COMM VITALITY / 1000WALNUT: 48 (3.32 %)\n",
      "BOULDER / REC CENTER: 40 (3.51 %)\n",
      "BOULDER / BASELINE ST1: 42 (3.53 %)\n",
      "BOULDER / ATRIUM ST1: 65 (6.58 %)\n",
      "COMM VITALITY / 1400 WALNUT1: 38 (7.29 %)\n",
      "COMM VITALITY / 1500PEARL: 41 (4.5 %)\n",
      "COMM VITALITY / BOULDER JCTN: 40 (5.28 %)\n",
      "COMM VITALITY / 1100WALNUT1: 39 (3.51 %)\n",
      "BOULDER / N BOULDER REC 1: 29 (2.07 %)\n",
      "\n",
      "The total amount of lost events: 439 (4.08 %)\n"
     ]
    }
   ],
   "source": [
    "# remove outliers\n",
    "drop_index = [] # list of indexes to keep\n",
    "names = df['Station_Name'].unique()\n",
    "\n",
    "for name in names:\n",
    "    temp = df[df['Station_Name'] == name]\n",
    "    # Get interquantile ranges\n",
    "    Q1, Q3 = temp.life_time.quantile([0.25, 0.75])\n",
    "    IQR = Q3-Q1\n",
    "    minimum = Q1 - 1.5*IQR\n",
    "    maximum = Q3 + 1.5*IQR\n",
    "    # Define observations which should be removed\n",
    "    temp2 = df[(df['life_time'] < minimum) | (df['life_time'] > maximum) &\n",
    "                  (df['Station_Name'] == name)]\n",
    "    print(\"{n}: {s} ({p} %)\".format(n=name, \n",
    "                                    s=temp2.shape[0], \n",
    "                                    p=round((temp2.shape[0]/temp.shape[0])*100,2)))\n",
    "    # Add the indexes which should be dropped\n",
    "    drop_index.extend(list(temp2.index))\n",
    "    \n",
    "print(\"\\nThe total amount of lost events: {n} ({p} %)\".format(n=len(drop_index), \n",
    "                                                              p=round(len(drop_index)/df.shape[0]*100,2)))\n",
    "\n",
    "df = df.drop(drop_index)\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "circular-rouge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10323, 71)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flush-copyright",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "comparative-bridges",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "suited-pavilion",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To test model\n",
    "def test_model(y_test, y_pred):\n",
    "    MAE = metrics.mean_absolute_error(y_test, y_pred)\n",
    "    #print('MAE (Mean Absolute Error):', MAE)\n",
    "    MSE = metrics.mean_squared_error(y_test, y_pred)\n",
    "    #print('MSE (Mean Squared Error):', MSE)\n",
    "    RMSE = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "    #print('RMSE (Root Mean Squared Error):', RMSE)\n",
    "    MAPE = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    \n",
    "    NRMSE = RMSE/np.mean(y_test)\n",
    "    return MAE, RMSE, MSE, MAPE, NRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "answering-effectiveness",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekdays = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "positions = [0,1,2,3,4,5,6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caring-killer",
   "metadata": {},
   "source": [
    "### Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-confidentiality",
   "metadata": {},
   "source": [
    "Add aggregated features for modeling purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "julian-wesley",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hour_label(X):\n",
    "    if (X >= 7) & (X <= 10):\n",
    "        return 'Morning'\n",
    "    elif (X >= 11) & (X <= 14):\n",
    "        return 'Midday'\n",
    "    elif (X >= 15) & (X <= 18):\n",
    "        return 'Afternoon'\n",
    "    elif (X >= 19) or (X < 1):\n",
    "        return 'Evening'\n",
    "    elif (X >= 1) & (X <= 6):\n",
    "        return 'Night'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aquatic-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add time of day and day of week\n",
    "df['tod'] = df['hour_b'].apply(hour_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "textile-balance",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['tod'] != 'Night']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acting-algeria",
   "metadata": {},
   "source": [
    "Limit to 4 stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "smooth-boundary",
   "metadata": {},
   "outputs": [],
   "source": [
    "station_subset = ['BOULDER / N BOULDER REC 1', 'COMM VITALITY / 1000WALNUT', \n",
    "        'COMM VITALITY / 1104 SPRUCE1', 'BOULDER / BASELINE ST1']\n",
    "df_stat = df[df['Station_Name'].isin(station_subset)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-primary",
   "metadata": {},
   "source": [
    "Add dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "lasting-socket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical features\n",
    "columns_categorical = ['weekday_b_name','tod','hour_b','Station_Name']\n",
    "df_stat = pd.get_dummies(df_stat, columns=columns_categorical, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-shopper",
   "metadata": {},
   "source": [
    "The models are renamed to make coding easier:\n",
    "- M1: Baseline\n",
    "- M2: Activity\n",
    "- M3: Temporal\n",
    "- M4: Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "toxic-basics",
   "metadata": {},
   "outputs": [],
   "source": [
    "## M1\n",
    "features1 = ['weekday_b_name_Monday', 'weekday_b_name_Saturday',\n",
    "             'weekday_b_name_Sunday', 'weekday_b_name_Thursday',\n",
    "             'weekday_b_name_Tuesday', 'weekday_b_name_Wednesday',\n",
    "             'tod_Evening','tod_Midday', 'tod_Morning',\n",
    "             'Station_Name_BOULDER / N BOULDER REC 1',\n",
    "             'Station_Name_COMM VITALITY / 1000WALNUT',\n",
    "             'Station_Name_COMM VITALITY / 1104 SPRUCE1'] # dow + tod\n",
    "\n",
    "## M5\n",
    "features2_cat = ['weekday_b_name_Monday', 'weekday_b_name_Saturday',\n",
    "                 'weekday_b_name_Sunday', 'weekday_b_name_Thursday',\n",
    "                 'weekday_b_name_Tuesday', 'weekday_b_name_Wednesday',\n",
    "                 'tod_Evening','tod_Midday', 'tod_Morning',\n",
    "                 'Station_Name_BOULDER / N BOULDER REC 1',\n",
    "                 'Station_Name_COMM VITALITY / 1000WALNUT',\n",
    "                 'Station_Name_COMM VITALITY / 1104 SPRUCE1']\n",
    "features2_con = ['lag1', 'lag2', 'lag3','near_charge_time_4H', 'near_charge_energy_4H',\n",
    "                 'charge_time_4H', 'charge_energy_4H','service'] # dow + agg. tod + lag + activ.\n",
    "\n",
    "## M5\n",
    "features3_cat = ['weekday_b_name_Monday', 'weekday_b_name_Saturday',\n",
    "                 'weekday_b_name_Sunday', 'weekday_b_name_Thursday',\n",
    "                 'weekday_b_name_Tuesday', 'weekday_b_name_Wednesday',\n",
    "                 'tod_Evening','tod_Midday', 'tod_Morning',\n",
    "                 'Station_Name_BOULDER / N BOULDER REC 1',\n",
    "                 'Station_Name_COMM VITALITY / 1000WALNUT',\n",
    "                 'Station_Name_COMM VITALITY / 1104 SPRUCE1']\n",
    "features3_con = ['service', 'entertainment', 'food', \n",
    "                 'childcare', 'medical', 'education','parking', 'waste-management'] # dow + agg. tod + lag + activ.\n",
    "\n",
    "## M5\n",
    "features4_cat = ['weekday_b_name_Monday', 'weekday_b_name_Saturday',\n",
    "                 'weekday_b_name_Sunday', 'weekday_b_name_Thursday',\n",
    "                 'weekday_b_name_Tuesday', 'weekday_b_name_Wednesday',\n",
    "                 'tod_Evening','tod_Midday', 'tod_Morning',\n",
    "                 'Station_Name_BOULDER / N BOULDER REC 1',\n",
    "                 'Station_Name_COMM VITALITY / 1000WALNUT',\n",
    "                 'Station_Name_COMM VITALITY / 1104 SPRUCE1']\n",
    "features4_con = ['lag1', 'lag2', 'lag3','near_charge_time_4H', 'near_charge_energy_4H',\n",
    "                 'charge_time_4H', 'charge_energy_4H','service', 'entertainment', 'food', \n",
    "                 'childcare', 'medical', 'education','parking', 'waste-management'] # dow + agg. tod + lag + activ.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immune-watts",
   "metadata": {},
   "source": [
    "Test train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "alike-serbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fourth-cemetery",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose data\n",
    "df_stat = df_stat.sort_values(by=['datetime_start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "above-thomson",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (4088, 97)\n",
      "Testing shape: (1022, 97)\n"
     ]
    }
   ],
   "source": [
    "train, test = np.split(df_stat, [int(split * len(df_stat))])\n",
    "print(\"Training shape:\",train.shape)\n",
    "print(\"Testing shape:\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "found-cover",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get X\n",
    "#M1 - Baseline\n",
    "X_train1, X_test1 = train[features1], test[features1]\n",
    "# M2 - Activity\n",
    "X_train2, X_test2 = train[features2_cat+features2_con], test[features2_cat+features2_con]\n",
    "scaler = StandardScaler()\n",
    "X_train2[features2_con] = scaler.fit_transform(X_train2[features2_con])\n",
    "X_test2[features2_con] = scaler.transform(X_test2[features2_con])\n",
    "# M3 - Spatial\n",
    "X_train3, X_test3 = train[features3_cat+features3_con], test[features3_cat+features3_con]\n",
    "scaler = StandardScaler()\n",
    "X_train3[features3_con] = scaler.fit_transform(X_train3[features3_con])\n",
    "X_test3[features3_con] = scaler.transform(X_test3[features3_con])\n",
    "# M4 - Full\n",
    "X_train4, X_test4 = train[features4_cat+features4_con], test[features4_cat+features4_con]\n",
    "scaler = StandardScaler()\n",
    "X_train4[features4_con] = scaler.fit_transform(X_train4[features4_con])\n",
    "X_test4[features4_con] = scaler.transform(X_test4[features4_con])\n",
    "\n",
    "## Get y - train\n",
    "y_train, y_test = train['life_time'], test['life_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "distributed-interstate",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "narrow-destiny",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_bootstraps = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-salvation",
   "metadata": {},
   "source": [
    "### LINEAR REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "approximate-fighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_lr = {'alpha':[0.001,0.01,0.1,0.5,1,3,5,7,10,13,15,20], 'fit_intercept':['True','False']}\n",
    "results['LR'] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-nomination",
   "metadata": {},
   "source": [
    "#### Linear regression - model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "prime-layer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'fit_intercept': 'True', 'alpha': 15}\n"
     ]
    }
   ],
   "source": [
    "results['LR']['M1'] = {}\n",
    "\n",
    "## Find hyperparam\n",
    "reg = Ridge(random_state=42)\n",
    "reg_gs = RandomizedSearchCV(reg, grid_lr, random_state=42, cv=5, \n",
    "                            n_iter=50, scoring='neg_mean_squared_error')\n",
    "reg_gs.fit(X_train1,y_train)\n",
    "param = reg_gs.best_params_\n",
    "print(\"Best parameters:\", param)\n",
    "\n",
    "# Fit model\n",
    "reg = Ridge(random_state=42, alpha=param['alpha'])\n",
    "reg.fit(X_train1,y_train)\n",
    "\n",
    "## Predict\n",
    "y_test_pred = reg.predict(X_test1)\n",
    "y_train_pred = reg.predict(X_train1)\n",
    "\n",
    "## Get metrics\n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(y_test,y_test_pred)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(y_train,y_train_pred)\n",
    "\n",
    "## Save results\n",
    "results['LR']['M1'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                          'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                          'rsq_train':reg.score(X_train1,y_train), \n",
    "                          'rsq_test':reg.score(X_test1,y_test),\n",
    "                          'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                          'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-thought",
   "metadata": {},
   "source": [
    "#### LR - Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "included-joint",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'fit_intercept': 'True', 'alpha': 20}\n"
     ]
    }
   ],
   "source": [
    "results['LR']['M2'] = {}\n",
    "\n",
    "## Find hyperparam\n",
    "reg = Ridge(random_state=42)\n",
    "reg_gs = RandomizedSearchCV(reg, grid_lr, random_state=42, cv=5, \n",
    "                            n_iter=50, scoring='neg_mean_squared_error')\n",
    "reg_gs.fit(X_train2,y_train)\n",
    "param = reg_gs.best_params_\n",
    "print(\"Best parameters:\", param)\n",
    "\n",
    "# Fit model\n",
    "reg = Ridge(random_state=42, alpha=param['alpha'])\n",
    "reg.fit(X_train2,y_train)\n",
    "\n",
    "## Predict\n",
    "y_test_pred = reg.predict(X_test2)\n",
    "y_train_pred = reg.predict(X_train2)\n",
    "\n",
    "## Get metrics\n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(y_test,y_test_pred)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(y_train,y_train_pred)\n",
    "\n",
    "## Save results\n",
    "results['LR']['M2'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                          'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                          'rsq_train':reg.score(X_train2,y_train), \n",
    "                          'rsq_test':reg.score(X_test2,y_test),\n",
    "                          'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                          'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confidential-reality",
   "metadata": {},
   "source": [
    "#### LR - Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "formal-corner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'fit_intercept': 'True', 'alpha': 20}\n"
     ]
    }
   ],
   "source": [
    "results['LR']['M3'] = {}\n",
    "\n",
    "## Find hyperparam\n",
    "reg = Ridge(random_state=42)\n",
    "reg_gs = RandomizedSearchCV(reg, grid_lr, random_state=42, cv=5, \n",
    "                            n_iter=50, scoring='neg_mean_squared_error')\n",
    "reg_gs.fit(X_train3,y_train)\n",
    "param = reg_gs.best_params_\n",
    "print(\"Best parameters:\", param)\n",
    "\n",
    "# Fit model\n",
    "reg = Ridge(random_state=42, alpha=param['alpha'])\n",
    "reg.fit(X_train3,y_train)\n",
    "\n",
    "## Predict\n",
    "y_test_pred = reg.predict(X_test3)\n",
    "y_train_pred = reg.predict(X_train3)\n",
    "\n",
    "## Get metrics\n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(y_test,y_test_pred)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(y_train,y_train_pred)\n",
    "\n",
    "## Save results\n",
    "results['LR']['M3'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                          'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                          'rsq_train':reg.score(X_train3,y_train), \n",
    "                          'rsq_test':reg.score(X_test3,y_test),\n",
    "                          'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                          'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "streaming-pottery",
   "metadata": {},
   "source": [
    "#### LR - Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "emerging-murder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'fit_intercept': 'True', 'alpha': 20}\n"
     ]
    }
   ],
   "source": [
    "results['LR']['M4'] = {}\n",
    "\n",
    "## Find hyperparam\n",
    "reg = Ridge(random_state=42)\n",
    "reg_gs = RandomizedSearchCV(reg, grid_lr, random_state=42, cv=5, \n",
    "                            n_iter=50, scoring='neg_mean_squared_error')\n",
    "reg_gs.fit(X_train4,y_train)\n",
    "param = reg_gs.best_params_\n",
    "print(\"Best parameters:\", param)\n",
    "\n",
    "# Fit model\n",
    "reg = Ridge(random_state=42, alpha=param['alpha'])\n",
    "reg.fit(X_train4,y_train)\n",
    "\n",
    "## Predict\n",
    "y_test_pred = reg.predict(X_test4)\n",
    "y_train_pred = reg.predict(X_train4)\n",
    "\n",
    "## Get metrics\n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(y_test,y_test_pred)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(y_train,y_train_pred)\n",
    "\n",
    "## Save results\n",
    "results['LR']['M4'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                          'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                          'rsq_train':reg.score(X_train4,y_train), \n",
    "                          'rsq_test':reg.score(X_test4,y_test),\n",
    "                          'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                          'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharing-criminal",
   "metadata": {},
   "source": [
    "### RANDOM FOREST REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "difficult-conviction",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_RF = {'n_estimators':[100,300,500,1000], 'min_samples_split':[2,3,5,7],\n",
    "           'min_samples_leaf':[3,5,10,15], 'max_depth':[2,3,5,7]}\n",
    "results['RF'] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-bicycle",
   "metadata": {},
   "source": [
    "#### Random forest regressor - model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "focal-traveler",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 500, 'min_samples_split': 2, 'min_samples_leaf': 15, 'max_depth': 7}\n"
     ]
    }
   ],
   "source": [
    "results['RF']['M1'] = {}\n",
    "\n",
    "## Find hyperparam\n",
    "reg = RandomForestRegressor(random_state=42)\n",
    "reg_gs = RandomizedSearchCV(reg, grid_RF, random_state=42, cv=5, \n",
    "                            n_iter=50, scoring='neg_mean_squared_error')\n",
    "reg_gs.fit(X_train1,y_train)\n",
    "param = reg_gs.best_params_\n",
    "print(\"Best parameters:\", param)\n",
    "reg = RandomForestRegressor(random_state=42, \n",
    "                            min_samples_split=param['min_samples_split'],\n",
    "                            min_samples_leaf=param['min_samples_leaf'],\n",
    "                            max_depth=param['max_depth'],\n",
    "                            n_estimators=param['n_estimators'])    \n",
    "reg.fit(X_train1, y_train) \n",
    "\n",
    "## Predict\n",
    "y_test_pred = reg.predict(X_test1)\n",
    "y_train_pred = reg.predict(X_train1)\n",
    "\n",
    "## Get metrics\n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(y_test,y_test_pred)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(y_train,y_train_pred)\n",
    "\n",
    "## Save results\n",
    "results['RF']['M1'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                          'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                          'rsq_train':reg.score(X_train1,y_train), \n",
    "                          'rsq_test':reg.score(X_test1,y_test),\n",
    "                          'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                          'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-segment",
   "metadata": {},
   "source": [
    "#### RF - M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "foreign-yeast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 300, 'min_samples_split': 7, 'min_samples_leaf': 15, 'max_depth': 7}\n"
     ]
    }
   ],
   "source": [
    "results['RF']['M2'] = {}\n",
    "\n",
    "reg = RandomForestRegressor(random_state=42)\n",
    "reg_gs = RandomizedSearchCV(reg, grid_RF, random_state=42, cv=5, \n",
    "                            n_iter=50, scoring='neg_mean_squared_error')\n",
    "reg_gs.fit(X_train2,y_train)\n",
    "param = reg_gs.best_params_\n",
    "print(\"Best parameters:\", param)\n",
    "reg = RandomForestRegressor(random_state=42, \n",
    "                            min_samples_split=param['min_samples_split'],\n",
    "                            min_samples_leaf=param['min_samples_leaf'],\n",
    "                            max_depth=param['max_depth'],\n",
    "                            n_estimators=param['n_estimators'])    \n",
    "reg.fit(X_train2, y_train) \n",
    "\n",
    "## Predict\n",
    "y_test_pred = reg.predict(X_test2)\n",
    "y_train_pred = reg.predict(X_train2)\n",
    "\n",
    "## Get metrics\n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(y_test,y_test_pred)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(y_train,y_train_pred)\n",
    "\n",
    "## Save results\n",
    "results['RF']['M2'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                          'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                          'rsq_train':reg.score(X_train2,y_train), \n",
    "                          'rsq_test':reg.score(X_test2,y_test),\n",
    "                          'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                          'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-marketing",
   "metadata": {},
   "source": [
    "#### RF - M3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "functional-relation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 500, 'min_samples_split': 2, 'min_samples_leaf': 15, 'max_depth': 7}\n"
     ]
    }
   ],
   "source": [
    "results['RF']['M3'] = {}\n",
    "\n",
    "reg = RandomForestRegressor(random_state=42)\n",
    "reg_gs = RandomizedSearchCV(reg, grid_RF, random_state=42, cv=5, \n",
    "                            n_iter=50, scoring='neg_mean_squared_error')\n",
    "reg_gs.fit(X_train3,y_train)\n",
    "param = reg_gs.best_params_\n",
    "print(\"Best parameters:\", param)\n",
    "reg = RandomForestRegressor(random_state=42, \n",
    "                            min_samples_split=param['min_samples_split'],\n",
    "                            min_samples_leaf=param['min_samples_leaf'],\n",
    "                            max_depth=param['max_depth'],\n",
    "                            n_estimators=param['n_estimators'])    \n",
    "reg.fit(X_train3, y_train) \n",
    "\n",
    "## Predict\n",
    "y_test_pred = reg.predict(X_test3)\n",
    "y_train_pred = reg.predict(X_train3)\n",
    "\n",
    "## Get metrics\n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(y_test,y_test_pred)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(y_train,y_train_pred)\n",
    "\n",
    "## Save results\n",
    "results['RF']['M3'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                          'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                          'rsq_train':reg.score(X_train3,y_train), \n",
    "                          'rsq_test':reg.score(X_test3,y_test),\n",
    "                          'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                          'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equipped-digit",
   "metadata": {},
   "source": [
    "#### RF - M4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bacterial-religion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 500, 'min_samples_split': 3, 'min_samples_leaf': 10, 'max_depth': 7}\n"
     ]
    }
   ],
   "source": [
    "results['RF']['M4'] = {}\n",
    "\n",
    "reg = RandomForestRegressor(random_state=42)\n",
    "reg_gs = RandomizedSearchCV(reg, grid_RF, random_state=42, cv=5, \n",
    "                            n_iter=50, scoring='neg_mean_squared_error')\n",
    "reg_gs.fit(X_train4,y_train)\n",
    "param = reg_gs.best_params_\n",
    "print(\"Best parameters:\", param)\n",
    "reg = RandomForestRegressor(random_state=42, \n",
    "                            min_samples_split=param['min_samples_split'],\n",
    "                            min_samples_leaf=param['min_samples_leaf'],\n",
    "                            max_depth=param['max_depth'],\n",
    "                            n_estimators=param['n_estimators'])    \n",
    "reg.fit(X_train4, y_train) \n",
    "\n",
    "## Predict\n",
    "y_test_pred = reg.predict(X_test4)\n",
    "y_train_pred = reg.predict(X_train4)\n",
    "\n",
    "## Get metrics\n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(y_test,y_test_pred)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(y_train,y_train_pred)\n",
    "\n",
    "## Save results\n",
    "results['RF']['M4'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                          'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                          'rsq_train':reg.score(X_train4,y_train), \n",
    "                          'rsq_test':reg.score(X_test4,y_test),\n",
    "                          'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                          'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-canal",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "representative-tomorrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_MLP = {'alpha':[0.0001,0.001,0.1,1,2,5,10], 'hidden_layer_sizes':\n",
    "            [(32),(32,32),(32,32),(32,32,32,32),(64),(64,64),(64,64,64),(64,64,64,64),\n",
    "             (128),(128,128),(128,128,128),(128,128,128,128),(256),(256,256),(256,256,256),\n",
    "             (256,256,256,256)],\n",
    "            'activation': ['tanh', 'relu', 'logistic']}\n",
    "results['MLP'] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-building",
   "metadata": {},
   "source": [
    "#### MLP - Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "tropical-cigarette",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'hidden_layer_sizes': (128, 128, 128, 128), 'alpha': 0.001, 'activation': 'relu'}\n"
     ]
    }
   ],
   "source": [
    "results['MLP']['M1'] = {}\n",
    "\n",
    "## Find hyperparam\n",
    "reg = MLPRegressor(random_state=42, max_iter=500, early_stopping=True)\n",
    "reg_gs = RandomizedSearchCV(reg, grid_MLP, random_state=42, n_iter=50,\n",
    "                            cv=5, scoring='neg_mean_squared_error')\n",
    "reg_gs.fit(X_train1,y_train)\n",
    "param = reg_gs.best_params_\n",
    "print(\"Best parameters:\", param)\n",
    "reg = MLPRegressor(random_state=42, alpha=param['alpha'], \n",
    "                   hidden_layer_sizes=param['hidden_layer_sizes'],\n",
    "                   activation = param['activation'],max_iter=500, early_stopping=True)\n",
    "reg.fit(X_train1, y_train)  \n",
    "\n",
    "## Predict\n",
    "y_test_pred = reg.predict(X_test1)\n",
    "y_train_pred = reg.predict(X_train1)\n",
    "\n",
    "## Get metrics\n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(y_test,y_test_pred)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(y_train,y_train_pred)\n",
    "\n",
    "## Save results\n",
    "results['MLP']['M1'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                          'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                          'rsq_train':reg.score(X_train1,y_train), \n",
    "                          'rsq_test':reg.score(X_test1,y_test),\n",
    "                          'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                          'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crazy-grace",
   "metadata": {},
   "source": [
    "#### MLP - M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "surprised-arena",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'hidden_layer_sizes': 256, 'alpha': 10, 'activation': 'tanh'}\n"
     ]
    }
   ],
   "source": [
    "results['MLP']['M2'] = {}\n",
    "\n",
    "reg = MLPRegressor(random_state=42, max_iter=500, early_stopping=True)\n",
    "reg_gs = RandomizedSearchCV(reg, grid_MLP, random_state=42, n_iter=50,\n",
    "                            cv=5, scoring='neg_mean_squared_error')\n",
    "reg_gs.fit(X_train2,y_train)\n",
    "param = reg_gs.best_params_\n",
    "print(\"Best parameters:\", param)\n",
    "reg = MLPRegressor(random_state=42, alpha=param['alpha'], \n",
    "                   hidden_layer_sizes=param['hidden_layer_sizes'],\n",
    "                   activation = param['activation'],max_iter=500, early_stopping=True)\n",
    "reg.fit(X_train2, y_train)\n",
    "\n",
    "## Predict\n",
    "y_test_pred = reg.predict(X_test2)\n",
    "y_train_pred = reg.predict(X_train2)\n",
    "\n",
    "## Get metrics\n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(y_test,y_test_pred)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(y_train,y_train_pred)\n",
    "\n",
    "## Save results\n",
    "results['MLP']['M2'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                          'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                          'rsq_train':reg.score(X_train2,y_train), \n",
    "                          'rsq_test':reg.score(X_test2,y_test),\n",
    "                          'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                          'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "specialized-census",
   "metadata": {},
   "source": [
    "#### MLP - M3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fantastic-enterprise",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'hidden_layer_sizes': (64, 64, 64, 64), 'alpha': 5, 'activation': 'relu'}\n"
     ]
    }
   ],
   "source": [
    "results['MLP']['M3'] = {}\n",
    "\n",
    "reg = MLPRegressor(random_state=42, max_iter=500, early_stopping=True)\n",
    "reg_gs = RandomizedSearchCV(reg, grid_MLP, random_state=42, n_iter=50,\n",
    "                            cv=5, scoring='neg_mean_squared_error')\n",
    "reg_gs.fit(X_train3,y_train)\n",
    "param = reg_gs.best_params_\n",
    "print(\"Best parameters:\", param)\n",
    "reg = MLPRegressor(random_state=42, alpha=param['alpha'], \n",
    "                   hidden_layer_sizes=param['hidden_layer_sizes'],\n",
    "                   activation = param['activation'],max_iter=500, early_stopping=True)\n",
    "reg.fit(X_train3, y_train)\n",
    "\n",
    "## Predict\n",
    "y_test_pred = reg.predict(X_test3)\n",
    "y_train_pred = reg.predict(X_train3)\n",
    "\n",
    "## Get metrics\n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(y_test,y_test_pred)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(y_train,y_train_pred)\n",
    "\n",
    "## Save results\n",
    "results['MLP']['M3'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                          'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                          'rsq_train':reg.score(X_train3,y_train), \n",
    "                          'rsq_test':reg.score(X_test3,y_test),\n",
    "                          'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                          'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-knife",
   "metadata": {},
   "source": [
    "#### MLP - M4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "quiet-puzzle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'hidden_layer_sizes': 256, 'alpha': 0.001, 'activation': 'relu'}\n"
     ]
    }
   ],
   "source": [
    "results['MLP']['M4'] = {}\n",
    "\n",
    "reg = MLPRegressor(random_state=42, max_iter=500, early_stopping=True)\n",
    "reg_gs = RandomizedSearchCV(reg, grid_MLP, random_state=42, n_iter=50,\n",
    "                            cv=5, scoring='neg_mean_squared_error')\n",
    "reg_gs.fit(X_train4,y_train)\n",
    "param = reg_gs.best_params_\n",
    "print(\"Best parameters:\", param)\n",
    "reg = MLPRegressor(random_state=42, alpha=param['alpha'], \n",
    "                   hidden_layer_sizes=param['hidden_layer_sizes'],\n",
    "                   activation = param['activation'],max_iter=500, early_stopping=True)\n",
    "reg.fit(X_train4, y_train)\n",
    "\n",
    "## Predict\n",
    "\n",
    "y_test_pred = reg.predict(X_test4)\n",
    "y_train_pred = reg.predict(X_train4)\n",
    "\n",
    "## Get metrics\n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(y_test,y_test_pred)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(y_train,y_train_pred)\n",
    "\n",
    "## Save results\n",
    "results['MLP']['M4'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                          'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                          'rsq_train':reg.score(X_train4,y_train), \n",
    "                          'rsq_test':reg.score(X_test4,y_test),\n",
    "                          'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                          'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-parish",
   "metadata": {},
   "source": [
    "### GRADIANT BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "proof-verification",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_GB = {'max_depth':[2,3,5,10],'n_estimators':[100,300,500,1000], \n",
    "           'learning_rate':[0.001,0.01,0.1,0.5,0.9], 'min_samples_split':[2,3,5,7],\n",
    "           'min_samples_leaf':[3,5,10,15]}\n",
    "results['GB'] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-melbourne",
   "metadata": {},
   "source": [
    "#### Gradiant boosting - M1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "qualified-anger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 500, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_depth': 2, 'learning_rate': 0.5}\n"
     ]
    }
   ],
   "source": [
    "results['GB']['M1'] = {}\n",
    "\n",
    "reg = GradientBoostingRegressor(random_state=42)\n",
    "reg_gs = RandomizedSearchCV(reg, grid_GB, random_state=42, n_iter = 50, \n",
    "                            cv=5, scoring='neg_mean_squared_error')\n",
    "reg_gs.fit(X_train1,y_train)\n",
    "param = reg_gs.best_params_\n",
    "print(\"Best parameters:\", param)\n",
    "reg = GradientBoostingRegressor(random_state=42, \n",
    "                                max_depth=param['max_depth'],\n",
    "                                min_samples_split=param['min_samples_split'],\n",
    "                                min_samples_leaf=param['min_samples_leaf'],\n",
    "                                n_estimators=param['n_estimators'], \n",
    "                                learning_rate=param['learning_rate'])\n",
    "reg.fit(X_train1, y_train)\n",
    "\n",
    "## Predict\n",
    "y_test_pred = reg.predict(X_test1)\n",
    "y_train_pred = reg.predict(X_train1)\n",
    "\n",
    "## Get metrics\n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(y_test,y_test_pred)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(y_train,y_train_pred)\n",
    "\n",
    "## Save results\n",
    "results['GB']['M1'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                          'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                          'rsq_train':reg.score(X_train1,y_train), \n",
    "                          'rsq_test':reg.score(X_test1,y_test),\n",
    "                          'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                          'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ahead-honey",
   "metadata": {},
   "source": [
    "#### GB - M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "resident-powell",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 300, 'min_samples_split': 3, 'min_samples_leaf': 5, 'max_depth': 5, 'learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "results['GB']['M2'] = {}\n",
    "\n",
    "reg = GradientBoostingRegressor(random_state=42)\n",
    "reg_gs = RandomizedSearchCV(reg, grid_GB, random_state=42, n_iter = 50, \n",
    "                            cv=5, scoring='neg_mean_squared_error')\n",
    "reg_gs.fit(X_train2,y_train)\n",
    "param = reg_gs.best_params_\n",
    "print(\"Best parameters:\", param)\n",
    "reg = GradientBoostingRegressor(random_state=42, \n",
    "                                max_depth=param['max_depth'],\n",
    "                                min_samples_split=param['min_samples_split'],\n",
    "                                min_samples_leaf=param['min_samples_leaf'],\n",
    "                                n_estimators=param['n_estimators'], \n",
    "                                learning_rate=param['learning_rate'])\n",
    "reg.fit(X_train2, y_train)\n",
    "\n",
    "## Predict\n",
    "y_test_pred = reg.predict(X_test2)\n",
    "y_train_pred = reg.predict(X_train2)\n",
    "\n",
    "## Get metrics\n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(y_test,y_test_pred)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(y_train,y_train_pred)\n",
    "\n",
    "## Save results\n",
    "results['GB']['M2'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                          'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                          'rsq_train':reg.score(X_train2,y_train), \n",
    "                          'rsq_test':reg.score(X_test2,y_test),\n",
    "                          'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                          'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simple-racing",
   "metadata": {},
   "source": [
    "#### GB - M3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "published-encoding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 300, 'min_samples_split': 3, 'min_samples_leaf': 5, 'max_depth': 5, 'learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "results['GB']['M3'] = {}\n",
    "\n",
    "reg = GradientBoostingRegressor(random_state=42)\n",
    "reg_gs = RandomizedSearchCV(reg, grid_GB, random_state=42, n_iter = 50, \n",
    "                            cv=5, scoring='neg_mean_squared_error')\n",
    "reg_gs.fit(X_train3,y_train)\n",
    "param = reg_gs.best_params_\n",
    "print(\"Best parameters:\", param)\n",
    "reg = GradientBoostingRegressor(random_state=42, \n",
    "                                max_depth=param['max_depth'],\n",
    "                                min_samples_split=param['min_samples_split'],\n",
    "                                min_samples_leaf=param['min_samples_leaf'],\n",
    "                                n_estimators=param['n_estimators'], \n",
    "                                learning_rate=param['learning_rate'])\n",
    "reg.fit(X_train3, y_train)\n",
    "\n",
    "## Predict\n",
    "y_test_pred = reg.predict(X_test3)\n",
    "y_train_pred = reg.predict(X_train3)\n",
    "\n",
    "## Get metrics\n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(y_test,y_test_pred)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(y_train,y_train_pred)\n",
    "\n",
    "## Save results\n",
    "results['GB']['M3'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                          'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                          'rsq_train':reg.score(X_train3,y_train), \n",
    "                          'rsq_test':reg.score(X_test3,y_test),\n",
    "                          'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                          'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "built-chicken",
   "metadata": {},
   "source": [
    "#### GB - M4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "driven-message",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 500, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_depth': 3, 'learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "results['GB']['M4'] = {}\n",
    "\n",
    "reg = GradientBoostingRegressor(random_state=42)\n",
    "reg_gs = RandomizedSearchCV(reg, grid_GB, random_state=42, n_iter = 50, \n",
    "                            cv=5, scoring='neg_mean_squared_error') \n",
    "reg_gs.fit(X_train4,y_train)\n",
    "param = reg_gs.best_params_\n",
    "print(\"Best parameters:\", param)\n",
    "reg = GradientBoostingRegressor(random_state=42, \n",
    "                                max_depth=param['max_depth'],\n",
    "                                min_samples_split=param['min_samples_split'],\n",
    "                                min_samples_leaf=param['min_samples_leaf'],\n",
    "                                n_estimators=param['n_estimators'], \n",
    "                                learning_rate=param['learning_rate'])\n",
    "reg.fit(X_train4, y_train)\n",
    "\n",
    "## Predict\n",
    "y_test_pred = reg.predict(X_test4)\n",
    "y_train_pred = reg.predict(X_train4)\n",
    "\n",
    "## Get metrics\n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(y_test,y_test_pred)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(y_train,y_train_pred)\n",
    "\n",
    "## Save results\n",
    "results['GB']['M4'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                          'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                          'rsq_train':reg.score(X_train4,y_train), \n",
    "                          'rsq_test':reg.score(X_test4,y_test),\n",
    "                          'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                          'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backed-trade",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "centered-tuesday",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR - M1:\n",
      " R2: 0.21 RMSE: 424.0 MAE: 328.0 MAPE: 1872.0 NRMSE: 0.92\n",
      "LR - M2:\n",
      " R2: 0.2 RMSE: 426.0 MAE: 328.0 MAPE: 1817.0 NRMSE: 0.92\n",
      "LR - M3:\n",
      " R2: 0.22 RMSE: 423.0 MAE: 327.0 MAPE: 1862.0 NRMSE: 0.92\n",
      "LR - M4:\n",
      " R2: 0.21 RMSE: 425.0 MAE: 327.0 MAPE: 1811.0 NRMSE: 0.92\n",
      "\n",
      "\n",
      "RF - M1:\n",
      " R2: 0.23 RMSE: 419.0 MAE: 321.0 MAPE: 1804.0 NRMSE: 0.91\n",
      "RF - M2:\n",
      " R2: 0.22 RMSE: 421.0 MAE: 323.0 MAPE: 1825.0 NRMSE: 0.91\n",
      "RF - M3:\n",
      " R2: 0.23 RMSE: 419.0 MAE: 320.0 MAPE: 1794.0 NRMSE: 0.91\n",
      "RF - M4:\n",
      " R2: 0.21 RMSE: 424.0 MAE: 323.0 MAPE: 1834.0 NRMSE: 0.92\n",
      "\n",
      "\n",
      "MLP - M1:\n",
      " R2: 0.24 RMSE: 417.0 MAE: 317.0 MAPE: 1744.0 NRMSE: 0.9\n",
      "MLP - M2:\n",
      " R2: 0.21 RMSE: 424.0 MAE: 324.0 MAPE: 1846.0 NRMSE: 0.92\n",
      "MLP - M3:\n",
      " R2: 0.24 RMSE: 416.0 MAE: 320.0 MAPE: 1798.0 NRMSE: 0.9\n",
      "MLP - M4:\n",
      " R2: 0.22 RMSE: 422.0 MAE: 324.0 MAPE: 1755.0 NRMSE: 0.91\n",
      "\n",
      "\n",
      "GB - M1:\n",
      " R2: 0.23 RMSE: 418.0 MAE: 319.0 MAPE: 1815.0 NRMSE: 0.91\n",
      "GB - M2:\n",
      " R2: 0.22 RMSE: 421.0 MAE: 328.0 MAPE: 1890.0 NRMSE: 0.91\n",
      "GB - M3:\n",
      " R2: 0.24 RMSE: 418.0 MAE: 323.0 MAPE: 1822.0 NRMSE: 0.9\n",
      "GB - M4:\n",
      " R2: 0.23 RMSE: 420.0 MAE: 327.0 MAPE: 1883.0 NRMSE: 0.91\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "methods = ['LR', 'RF', 'MLP', 'GB']\n",
    "models = ['M1','M2','M3','M4']\n",
    "\n",
    "for me in methods:\n",
    "    for mo in models:\n",
    "        r = results[me][mo]\n",
    "        RMSEtest = r['RMSE_test']\n",
    "        R2test = r['rsq_test']\n",
    "        MAEtest = r['MAE_test']\n",
    "        MAPE = r['MAPE_test']\n",
    "        NRMSE = r['NRMSE_test']\n",
    "        \n",
    "        print(\"{} - {}:\\n R2: {} RMSE: {} MAE: {} MAPE: {} NRMSE: {}\".format(me,mo,\n",
    "                                                                              round(np.mean(R2test),2),\n",
    "                                                                              round(np.mean(RMSEtest),0),\n",
    "                                                                              round(np.mean(MAEtest),0),\n",
    "                                                                              round(np.mean(MAPE),0),\n",
    "                                                                              round(np.mean(NRMSE),2)))        \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supreme-insurance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
