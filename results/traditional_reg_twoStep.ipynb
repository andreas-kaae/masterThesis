{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "linear-sunrise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import pickle\n",
    "import pickle5\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import r2_score   \n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import folium\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV, cross_val_score, cross_val_predict\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "## block warning\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "straight-termination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>life_time</th>\n",
       "      <th>datetime_start</th>\n",
       "      <th>datetime_end</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>distance_center_km</th>\n",
       "      <th>weekday_b</th>\n",
       "      <th>charging_ports</th>\n",
       "      <th>lag1</th>\n",
       "      <th>lag2</th>\n",
       "      <th>...</th>\n",
       "      <th>hour_b_22</th>\n",
       "      <th>hour_b_23</th>\n",
       "      <th>Station_Name_BOULDER / N BOULDER REC 1</th>\n",
       "      <th>Station_Name_COMM VITALITY / 1000WALNUT</th>\n",
       "      <th>Station_Name_COMM VITALITY / 1104 SPRUCE1</th>\n",
       "      <th>4Hsplit</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>Station_Name</th>\n",
       "      <th>weekday_b_name</th>\n",
       "      <th>tod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3734</th>\n",
       "      <td>118.5</td>\n",
       "      <td>2018-01-05 14:25:00</td>\n",
       "      <td>2018-01-05 16:23:30</td>\n",
       "      <td>40.000148</td>\n",
       "      <td>-105.282437</td>\n",
       "      <td>2.096847</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1271.5</td>\n",
       "      <td>135.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>BOULDER / BASELINE ST1</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Midday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3735</th>\n",
       "      <td>886.5</td>\n",
       "      <td>2018-01-05 17:02:00</td>\n",
       "      <td>2018-01-06 07:48:30</td>\n",
       "      <td>40.000148</td>\n",
       "      <td>-105.282437</td>\n",
       "      <td>2.096847</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>118.5</td>\n",
       "      <td>1271.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>BOULDER / BASELINE ST1</td>\n",
       "      <td>Friday</td>\n",
       "      <td>Afternoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3736</th>\n",
       "      <td>326.5</td>\n",
       "      <td>2018-01-06 09:28:00</td>\n",
       "      <td>2018-01-06 14:54:30</td>\n",
       "      <td>40.000148</td>\n",
       "      <td>-105.282437</td>\n",
       "      <td>2.096847</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>886.5</td>\n",
       "      <td>118.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>BOULDER / BASELINE ST1</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3737</th>\n",
       "      <td>996.5</td>\n",
       "      <td>2018-01-06 17:09:00</td>\n",
       "      <td>2018-01-07 09:45:30</td>\n",
       "      <td>40.000148</td>\n",
       "      <td>-105.282437</td>\n",
       "      <td>2.096847</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>326.5</td>\n",
       "      <td>886.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>BOULDER / BASELINE ST1</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>Afternoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3738</th>\n",
       "      <td>52.5</td>\n",
       "      <td>2018-01-07 10:58:00</td>\n",
       "      <td>2018-01-07 11:50:30</td>\n",
       "      <td>40.000148</td>\n",
       "      <td>-105.282437</td>\n",
       "      <td>2.096847</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>996.5</td>\n",
       "      <td>326.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BOULDER / BASELINE ST1</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>Morning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 102 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      life_time      datetime_start        datetime_end   latitude  \\\n",
       "3734      118.5 2018-01-05 14:25:00 2018-01-05 16:23:30  40.000148   \n",
       "3735      886.5 2018-01-05 17:02:00 2018-01-06 07:48:30  40.000148   \n",
       "3736      326.5 2018-01-06 09:28:00 2018-01-06 14:54:30  40.000148   \n",
       "3737      996.5 2018-01-06 17:09:00 2018-01-07 09:45:30  40.000148   \n",
       "3738       52.5 2018-01-07 10:58:00 2018-01-07 11:50:30  40.000148   \n",
       "\n",
       "       longitude  distance_center_km  weekday_b  charging_ports    lag1  \\\n",
       "3734 -105.282437            2.096847          4               2  1271.5   \n",
       "3735 -105.282437            2.096847          4               2   118.5   \n",
       "3736 -105.282437            2.096847          5               2   886.5   \n",
       "3737 -105.282437            2.096847          5               2   326.5   \n",
       "3738 -105.282437            2.096847          6               2   996.5   \n",
       "\n",
       "        lag2  ...  hour_b_22  hour_b_23  \\\n",
       "3734   135.5  ...          0          0   \n",
       "3735  1271.5  ...          0          0   \n",
       "3736   118.5  ...          0          0   \n",
       "3737   886.5  ...          0          0   \n",
       "3738   326.5  ...          0          0   \n",
       "\n",
       "      Station_Name_BOULDER / N BOULDER REC 1  \\\n",
       "3734                                       0   \n",
       "3735                                       0   \n",
       "3736                                       0   \n",
       "3737                                       0   \n",
       "3738                                       0   \n",
       "\n",
       "      Station_Name_COMM VITALITY / 1000WALNUT  \\\n",
       "3734                                        0   \n",
       "3735                                        0   \n",
       "3736                                        0   \n",
       "3737                                        0   \n",
       "3738                                        0   \n",
       "\n",
       "      Station_Name_COMM VITALITY / 1104 SPRUCE1  4Hsplit  y_pred  \\\n",
       "3734                                          0        0       1   \n",
       "3735                                          0        1       1   \n",
       "3736                                          0        1       0   \n",
       "3737                                          0        1       1   \n",
       "3738                                          0        0       0   \n",
       "\n",
       "                Station_Name  weekday_b_name        tod  \n",
       "3734  BOULDER / BASELINE ST1          Friday     Midday  \n",
       "3735  BOULDER / BASELINE ST1          Friday  Afternoon  \n",
       "3736  BOULDER / BASELINE ST1        Saturday    Morning  \n",
       "3737  BOULDER / BASELINE ST1        Saturday  Afternoon  \n",
       "3738  BOULDER / BASELINE ST1          Sunday    Morning  \n",
       "\n",
       "[5 rows x 102 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../data/ut_V6_classification-4H.pkl\", \"rb\") as fh:\n",
    "    df = pickle5.load(fh)\n",
    "    \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "unlikely-radius",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5110, 102)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "whole-imperial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y_pred\n",
       "0    3062\n",
       "1    2048\n",
       "Name: life_time, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['y_pred']).count().life_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flush-copyright",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "classical-robert",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "suited-pavilion",
   "metadata": {},
   "outputs": [],
   "source": [
    "## To test model\n",
    "def test_model(y_test, y_pred):\n",
    "    MAE = metrics.mean_absolute_error(y_test, y_pred)\n",
    "    #print('MAE (Mean Absolute Error):', MAE)\n",
    "    MSE = metrics.mean_squared_error(y_test, y_pred)\n",
    "    #print('MSE (Mean Squared Error):', MSE)\n",
    "    RMSE = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "    #print('RMSE (Root Mean Squared Error):', RMSE)\n",
    "    MAPE = mean_absolute_percentage_error(y_test, y_pred)\n",
    "    \n",
    "    NRMSE = RMSE/np.mean(y_test)\n",
    "    return MAE, RMSE, MSE, MAPE, NRMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "answering-effectiveness",
   "metadata": {},
   "outputs": [],
   "source": [
    "weekdays = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "positions = [0,1,2,3,4,5,6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordered-harvard",
   "metadata": {},
   "source": [
    "To make coding easier the models are renamed:\n",
    "- M1: Baseline\n",
    "- M5: Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "engaged-posting",
   "metadata": {},
   "outputs": [],
   "source": [
    "## M1\n",
    "features1 = ['weekday_b_name_Monday', 'weekday_b_name_Saturday',\n",
    "             'weekday_b_name_Sunday', 'weekday_b_name_Thursday',\n",
    "             'weekday_b_name_Tuesday', 'weekday_b_name_Wednesday',\n",
    "             'tod_Evening','tod_Midday', 'tod_Morning',\n",
    "             'Station_Name_BOULDER / N BOULDER REC 1',\n",
    "             'Station_Name_COMM VITALITY / 1000WALNUT',\n",
    "             'Station_Name_COMM VITALITY / 1104 SPRUCE1'] # dow + tod\n",
    "\n",
    "## M5\n",
    "features5_cat = ['weekday_b_name_Monday', 'weekday_b_name_Saturday',\n",
    "                 'weekday_b_name_Sunday', 'weekday_b_name_Thursday',\n",
    "                 'weekday_b_name_Tuesday', 'weekday_b_name_Wednesday',\n",
    "                 'tod_Evening','tod_Midday', 'tod_Morning',\n",
    "                 'Station_Name_BOULDER / N BOULDER REC 1',\n",
    "                 'Station_Name_COMM VITALITY / 1000WALNUT',\n",
    "                 'Station_Name_COMM VITALITY / 1104 SPRUCE1']\n",
    "features5_con = ['lag1', 'lag2', 'lag3','near_charge_time_4H', 'near_charge_energy_4H',\n",
    "                 'charge_time_4H', 'charge_energy_4H','service', 'entertainment', 'food', \n",
    "                 'childcare', 'medical', 'education', 'waste-management'] # dow + agg. tod + lag + activ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "alike-serbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "previous-pennsylvania",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "offshore-conjunction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shape: (4088, 102)\n",
      "Testing shape: (1022, 102)\n"
     ]
    }
   ],
   "source": [
    "train, test = np.split(df, [int(split * len(df))])\n",
    "print(\"Training shape:\",train.shape)\n",
    "print(\"Testing shape:\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "primary-chrome",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainS = train[train['y_pred'] == 0]\n",
    "trainL = train[train['y_pred'] == 1]\n",
    "\n",
    "testS = test[test['y_pred'] == 0]\n",
    "testL = test[test['y_pred'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "controlled-influence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHORT: Train: 2433 Test: 629\n",
      "LONG: Train: 1655 Test: 393\n"
     ]
    }
   ],
   "source": [
    "print(\"SHORT: Train: {} Test: {}\".format(trainS.shape[0], testS.shape[0]))\n",
    "print(\"LONG: Train: {} Test: {}\".format(trainL.shape[0], testL.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "charitable-taylor",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get X - train\n",
    "# Baseline\n",
    "X1_S = trainS[features1]\n",
    "X1_L = trainL[features1]\n",
    "\n",
    "## Get X - test\n",
    "# Baseline\n",
    "X1_S_test = testS[features1]\n",
    "X1_L_test = testL[features1]\n",
    "\n",
    "# Full\n",
    "X5_S = trainS[features5_cat+features5_con]\n",
    "scaler = StandardScaler()\n",
    "X5_S[features5_con] = scaler.fit_transform(X5_S[features5_con])\n",
    "X5_S_test = testS[features5_cat+features5_con]\n",
    "X5_S_test[features5_con] = scaler.transform(X5_S_test[features5_con])\n",
    "\n",
    "X5_L = trainL[features5_cat+features5_con]\n",
    "scaler = StandardScaler()\n",
    "X5_L[features5_con] = scaler.fit_transform(X5_L[features5_con])\n",
    "X5_L_test = testL[features5_cat+features5_con]\n",
    "X5_L_test[features5_con] = scaler.transform(X5_L_test[features5_con])\n",
    "\n",
    "## Get y - train\n",
    "y_S = trainS['life_time']\n",
    "y_L = trainL['life_time']\n",
    "\n",
    "## Get y - test\n",
    "y_S_test = testS['life_time']\n",
    "y_L_test = testL['life_time']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "digital-salvation",
   "metadata": {},
   "source": [
    "### LINEAR REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "approximate-fighter",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_lr = {'alpha':[0.001,0.01,0.1,0.5,1,3,5,7,10,13,15,20], 'fit_intercept':['True','False']}\n",
    "results['LR'] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "damaged-nomination",
   "metadata": {},
   "source": [
    "#### Linear regression - model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "satisfied-allocation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_intercept': 'True', 'alpha': 20}\n",
      "{'fit_intercept': 'True', 'alpha': 15}\n"
     ]
    }
   ],
   "source": [
    "#########################################################\n",
    "#################### SEPERATE RESULTS ###################\n",
    "\n",
    "results['LR']['M1'] = {}\n",
    "results['LR']['M1']['S'] = {}\n",
    "results['LR']['M1']['L'] = {}\n",
    "results['LR']['M1']['Com'] = {}\n",
    "\n",
    "####################### Hyperparameters #######################\n",
    "## get hyperparameters and fit models\n",
    "# short\n",
    "reg = Ridge(random_state=42)\n",
    "reg_gs = RandomizedSearchCV(reg, grid_lr, random_state=42, cv=5, \n",
    "                            n_iter=50, scoring='neg_mean_squared_error')\n",
    "reg_gs.fit(X1_S,y_S)\n",
    "paramS = reg_gs.best_params_\n",
    "print(paramS)\n",
    "# Fit model\n",
    "regs = Ridge(random_state=42, alpha=paramS['alpha'], fit_intercept=False)\n",
    "regs.fit(X1_S,y_S)\n",
    "\n",
    "# long\n",
    "reg = Ridge(random_state=42)\n",
    "reg_gs = RandomizedSearchCV(reg, grid_lr, random_state=42, cv=5, \n",
    "                            n_iter=50, scoring='neg_mean_squared_error')\n",
    "reg_gs.fit(X1_L,y_L)\n",
    "paramL = reg_gs.best_params_\n",
    "print(paramL)\n",
    "# Fit model\n",
    "regl = Ridge(random_state=42, alpha=paramL['alpha'], fit_intercept=False)\n",
    "regl.fit(X1_L,y_L)\n",
    "\n",
    "#################### Predictions and evaluate ####################\n",
    "########################### short\n",
    "## Predict\n",
    "y_test_predS = regs.predict(X1_S_test)\n",
    "y_train_predS = regs.predict(X1_S)\n",
    "\n",
    "## Get metrics  \n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(y_S_test,y_test_predS)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(y_S,y_train_predS)\n",
    "\n",
    "## Save results\n",
    "results['LR']['M1']['S'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                              'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                              'rsq_train':r2_score(y_S, y_train_predS), \n",
    "                              'rsq_test':r2_score(y_S_test, y_test_predS),\n",
    "                              'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                              'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train}\n",
    "\n",
    "########################### long\n",
    "## predict\n",
    "y_test_predL = regl.predict(X1_L_test)\n",
    "y_train_predL = regl.predict(X1_L)\n",
    "\n",
    "## Get metrics  \n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(y_L_test,y_test_predL)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(y_L,y_train_predL)\n",
    "\n",
    "## Save results\n",
    "results['LR']['M1']['L'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                              'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                              'rsq_train':r2_score(y_L, y_train_predL), \n",
    "                              'rsq_test':r2_score(y_L_test, y_test_predL),\n",
    "                              'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                              'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train}\n",
    "\n",
    "########################### combined\n",
    "y_com_real_test = pd.concat([y_S_test, y_L_test])\n",
    "y_com_pred_test = np.concatenate([y_test_predS,y_test_predL])\n",
    "y_com_real_train = pd.concat([y_S, y_L])\n",
    "y_com_pred_train = np.concatenate([y_train_predS,y_train_predL])\n",
    "\n",
    "## Get metrics  \n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(y_com_real_test,\n",
    "                                                                  y_com_pred_test)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(y_com_real_train,\n",
    "                                                                       y_com_pred_train)\n",
    "\n",
    "## Save results\n",
    "results['LR']['M1']['Com'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                              'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                              'rsq_train':r2_score(y_com_real_train,y_com_pred_train), \n",
    "                              'rsq_test':r2_score(y_com_real_test,y_com_pred_test),\n",
    "                              'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                              'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forty-timer",
   "metadata": {},
   "source": [
    "#### Linear Regression - M5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "occasional-patch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fit_intercept': 'True', 'alpha': 20}\n",
      "{'fit_intercept': 'True', 'alpha': 20}\n"
     ]
    }
   ],
   "source": [
    "#########################################################\n",
    "#################### SEPERATE RESULTS ###################\n",
    "\n",
    "results['LR']['M5'] = {}\n",
    "results['LR']['M5']['S'] = {}\n",
    "results['LR']['M5']['L'] = {}\n",
    "results['LR']['M5']['Com'] = {}\n",
    "\n",
    "####################### Hyperparameters #######################\n",
    "## get hyperparameters and fit models\n",
    "# short\n",
    "reg = Ridge(random_state=42)\n",
    "reg_gs = RandomizedSearchCV(reg, grid_lr, random_state=42, cv=5, \n",
    "                            n_iter=50, scoring='neg_mean_squared_error')\n",
    "reg_gs.fit(X5_S,y_S)\n",
    "paramS = reg_gs.best_params_\n",
    "print(paramS)\n",
    "# Fit model\n",
    "regs = Ridge(random_state=42, alpha=paramS['alpha'], fit_intercept=False)\n",
    "regs.fit(X5_S,y_S)\n",
    "\n",
    "# long\n",
    "reg = Ridge(random_state=42)\n",
    "reg_gs = RandomizedSearchCV(reg, grid_lr, random_state=42, cv=5, \n",
    "                            n_iter=50, scoring='neg_mean_squared_error')\n",
    "reg_gs.fit(X5_L,y_L)\n",
    "paramL = reg_gs.best_params_\n",
    "print(paramL)\n",
    "# Fit model\n",
    "regl = Ridge(random_state=42, alpha=paramL['alpha'], fit_intercept=False)\n",
    "regl.fit(X5_L,y_L)\n",
    "\n",
    "#################### Predictions and evaluate ####################\n",
    "########################### short\n",
    "## Predict\n",
    "y_test_predS = regs.predict(X5_S_test)\n",
    "y_train_predS = regs.predict(X5_S)\n",
    "\n",
    "## Get metrics  \n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(y_S_test,y_test_predS)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(y_S,y_train_predS)\n",
    "\n",
    "## Save results\n",
    "results['LR']['M5']['S'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                              'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                              'rsq_train':r2_score(y_S, y_train_predS), \n",
    "                              'rsq_test':r2_score(y_S_test, y_test_predS),\n",
    "                              'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                              'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train}\n",
    "\n",
    "########################### long\n",
    "## predict\n",
    "y_test_predL = regl.predict(X5_L_test)\n",
    "y_train_predL = regl.predict(X5_L)\n",
    "\n",
    "## Get metrics  \n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(y_L_test,y_test_predL)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(y_L,y_train_predL)\n",
    "\n",
    "## Save results\n",
    "results['LR']['M5']['L'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                              'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                              'rsq_train':r2_score(y_L, y_train_predL), \n",
    "                              'rsq_test':r2_score(y_L_test, y_test_predL),\n",
    "                              'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                              'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train}\n",
    "\n",
    "########################### combined\n",
    "y_com_real_test = pd.concat([y_S_test, y_L_test])\n",
    "y_com_pred_test = np.concatenate([y_test_predS,y_test_predL])\n",
    "y_com_real_train = pd.concat([y_S, y_L])\n",
    "y_com_pred_train = np.concatenate([y_train_predS,y_train_predL])\n",
    "\n",
    "## Get metrics  \n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(y_com_real_test,\n",
    "                                                                  y_com_pred_test)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(y_com_real_train,\n",
    "                                                                       y_com_pred_train)\n",
    "\n",
    "## Save results\n",
    "results['LR']['M5']['Com'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                              'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                              'rsq_train':r2_score(y_com_real_train,y_com_pred_train), \n",
    "                              'rsq_test':r2_score(y_com_real_test,y_com_pred_test),\n",
    "                              'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                              'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharing-criminal",
   "metadata": {},
   "source": [
    "### RANDOM FOREST REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "difficult-conviction",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_RF = {'n_estimators':[100,300,500,1000], 'min_samples_split':[2,3,5,7],\n",
    "           'min_samples_leaf':[3,5,10,15], 'max_depth':[2,3,5,7]}\n",
    "results['RF'] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "engaged-bicycle",
   "metadata": {},
   "source": [
    "#### Random forest regressor - model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "personalized-decimal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 100, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_depth': 3}\n",
      "{'n_estimators': 100, 'min_samples_split': 3, 'min_samples_leaf': 15, 'max_depth': 5}\n"
     ]
    }
   ],
   "source": [
    "#########################################################\n",
    "#################### SEPERATE RESULTS ###################\n",
    "\n",
    "results['RF']['M1'] = {}\n",
    "results['RF']['M1']['S'] = {}\n",
    "results['RF']['M1']['L'] = {}\n",
    "results['RF']['M1']['Com'] = {}\n",
    "\n",
    "####################### Hyperparameters #######################\n",
    "## get hyperparameters and fit models\n",
    "# short\n",
    "reg = RandomForestRegressor(random_state=42)\n",
    "reg_gs = RandomizedSearchCV(reg, grid_RF, random_state=42, cv=5, \n",
    "                            n_iter=50, scoring='neg_mean_squared_error')\n",
    "reg_gs.fit(X1_S,y_S)\n",
    "paramS = reg_gs.best_params_\n",
    "print(paramS)\n",
    "# Fit model\n",
    "regs = RandomForestRegressor(random_state=42, \n",
    "                            min_samples_split=paramS['min_samples_split'],\n",
    "                            min_samples_leaf=paramS['min_samples_leaf'],\n",
    "                            max_depth=paramS['max_depth'],\n",
    "                            n_estimators=paramS['n_estimators'])\n",
    "regs.fit(X1_S,y_S)\n",
    "\n",
    "# long\n",
    "reg = RandomForestRegressor(random_state=42)\n",
    "reg_gs = RandomizedSearchCV(reg, grid_RF, random_state=42, cv=5, \n",
    "                            n_iter=50, scoring='neg_mean_squared_error')\n",
    "reg_gs.fit(X1_L,y_L)\n",
    "paramL = reg_gs.best_params_\n",
    "print(paramL)\n",
    "# Fit model\n",
    "regl = RandomForestRegressor(random_state=42, \n",
    "                            min_samples_split=paramL['min_samples_split'],\n",
    "                            min_samples_leaf=paramL['min_samples_leaf'], \n",
    "                            max_depth=paramL['max_depth'],\n",
    "                            n_estimators=paramL['n_estimators'])\n",
    "regl.fit(X1_L,y_L)\n",
    "\n",
    "#################### Predictions and evaluate ####################\n",
    "########################### short\n",
    "## Predict\n",
    "y_test_predS = regs.predict(X1_S_test)\n",
    "y_train_predS = regs.predict(X1_S)\n",
    "\n",
    "## Get metrics  \n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(y_S_test,y_test_predS)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(y_S,y_train_predS)\n",
    "\n",
    "## Save results\n",
    "results['RF']['M1']['S'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                              'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                              'rsq_train':r2_score(y_S, y_train_predS), \n",
    "                              'rsq_test':r2_score(y_S_test, y_test_predS),\n",
    "                              'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                              'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train}\n",
    "\n",
    "########################### long\n",
    "## predict\n",
    "y_test_predL = regl.predict(X1_L_test)\n",
    "y_train_predL = regl.predict(X1_L)\n",
    "\n",
    "## Get metrics  \n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(y_L_test,y_test_predL)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(y_L,y_train_predL)\n",
    "\n",
    "## Save results\n",
    "results['RF']['M1']['L'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                              'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                              'rsq_train':r2_score(y_L, y_train_predL), \n",
    "                              'rsq_test':r2_score(y_L_test, y_test_predL),\n",
    "                              'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                              'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train}\n",
    "\n",
    "########################### combined\n",
    "y_com_real_test = pd.concat([y_S_test, y_L_test])\n",
    "y_com_pred_test = np.concatenate([y_test_predS,y_test_predL])\n",
    "y_com_real_train = pd.concat([y_S, y_L])\n",
    "y_com_pred_train = np.concatenate([y_train_predS,y_train_predL])\n",
    "\n",
    "## Get metrics  \n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(y_com_real_test,\n",
    "                                                                  y_com_pred_test)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(y_com_real_train,\n",
    "                                                                       y_com_pred_train)\n",
    "\n",
    "## Save results\n",
    "results['RF']['M1']['Com'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                              'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                              'rsq_train':r2_score(y_com_real_train,y_com_pred_train), \n",
    "                              'rsq_test':r2_score(y_com_real_test,y_com_pred_test),\n",
    "                              'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                              'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mighty-segment",
   "metadata": {},
   "source": [
    "#### RF - M5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "improving-variation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 500, 'min_samples_split': 2, 'min_samples_leaf': 15, 'max_depth': 7}\n",
      "{'n_estimators': 100, 'min_samples_split': 5, 'min_samples_leaf': 15, 'max_depth': 3}\n"
     ]
    }
   ],
   "source": [
    "#########################################################\n",
    "#################### SEPERATE RESULTS ###################\n",
    "\n",
    "results['RF']['M5'] = {}\n",
    "results['RF']['M5']['S'] = {}\n",
    "results['RF']['M5']['L'] = {}\n",
    "results['RF']['M5']['Com'] = {}\n",
    "\n",
    "####################### Hyperparameters #######################\n",
    "## get hyperparameters and fit models\n",
    "# short\n",
    "reg = RandomForestRegressor(random_state=42)\n",
    "reg_gs = RandomizedSearchCV(reg, grid_RF, random_state=42, cv=5, \n",
    "                            n_iter=50, scoring='neg_mean_squared_error')\n",
    "reg_gs.fit(X5_S,y_S)\n",
    "paramS = reg_gs.best_params_\n",
    "print(paramS)\n",
    "# Fit model\n",
    "regs = RandomForestRegressor(random_state=42, \n",
    "                            min_samples_split=paramS['min_samples_split'],\n",
    "                            min_samples_leaf=paramS['min_samples_leaf'],\n",
    "                            max_depth=paramS['max_depth'],\n",
    "                            n_estimators=paramS['n_estimators'])\n",
    "regs.fit(X5_S,y_S)\n",
    "\n",
    "# long\n",
    "reg = RandomForestRegressor(random_state=42)\n",
    "reg_gs = RandomizedSearchCV(reg, grid_RF, random_state=42, cv=5, \n",
    "                            n_iter=50, scoring='neg_mean_squared_error')\n",
    "reg_gs.fit(X5_L,y_L)\n",
    "paramL = reg_gs.best_params_\n",
    "print(paramL)\n",
    "# Fit model\n",
    "regl = RandomForestRegressor(random_state=42, \n",
    "                            min_samples_split=paramL['min_samples_split'],\n",
    "                            min_samples_leaf=paramL['min_samples_leaf'], \n",
    "                            max_depth=paramL['max_depth'],\n",
    "                            n_estimators=paramL['n_estimators'])\n",
    "regl.fit(X5_L,y_L)\n",
    "\n",
    "#################### Predictions and evaluate ####################\n",
    "########################### short\n",
    "## Predict\n",
    "y_test_predS = regs.predict(X5_S_test)\n",
    "y_train_predS = regs.predict(X5_S)\n",
    "\n",
    "## Get metrics  \n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(y_S_test,y_test_predS)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(y_S,y_train_predS)\n",
    "\n",
    "## Save results\n",
    "results['RF']['M5']['S'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                              'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                              'rsq_train':r2_score(y_S, y_train_predS), \n",
    "                              'rsq_test':r2_score(y_S_test, y_test_predS),\n",
    "                              'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                              'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train}\n",
    "\n",
    "########################### long\n",
    "## predict\n",
    "y_test_predL = regl.predict(X5_L_test)\n",
    "y_train_predL = regl.predict(X5_L)\n",
    "\n",
    "## Get metrics  \n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(y_L_test,y_test_predL)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(y_L,y_train_predL)\n",
    "\n",
    "## Save results\n",
    "results['RF']['M5']['L'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                              'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                              'rsq_train':r2_score(y_L, y_train_predL), \n",
    "                              'rsq_test':r2_score(y_L_test, y_test_predL),\n",
    "                              'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                              'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train}\n",
    "\n",
    "########################### combined\n",
    "y_com_real_test = pd.concat([y_S_test, y_L_test])\n",
    "y_com_pred_test = np.concatenate([y_test_predS,y_test_predL])\n",
    "y_com_real_train = pd.concat([y_S, y_L])\n",
    "y_com_pred_train = np.concatenate([y_train_predS,y_train_predL])\n",
    "\n",
    "## Get metrics  \n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(y_com_real_test,\n",
    "                                                                  y_com_pred_test)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(y_com_real_train,\n",
    "                                                                       y_com_pred_train)\n",
    "\n",
    "## Save results\n",
    "results['RF']['M5']['Com'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                              'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                              'rsq_train':r2_score(y_com_real_train,y_com_pred_train), \n",
    "                              'rsq_test':r2_score(y_com_real_test,y_com_pred_test),\n",
    "                              'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                              'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-canal",
   "metadata": {},
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "representative-tomorrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_MLP = {'alpha':[0.0001,0.001,0.1,1,2,5,10], 'hidden_layer_sizes':\n",
    "            [(32),(32,32),(32,32),(32,32,32,32),(64),(64,64),(64,64,64),(64,64,64,64),\n",
    "             (128),(128,128),(128,128,128),(128,128,128,128),(256),(256,256),(256,256,256),\n",
    "             (256,256,256,256)],\n",
    "            'activation': ['tanh', 'relu', 'logistic']}\n",
    "results['MLP'] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-building",
   "metadata": {},
   "source": [
    "#### MLP - Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "illegal-vienna",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_layer_sizes': (256, 256, 256), 'alpha': 0.1, 'activation': 'relu'}\n",
      "{'hidden_layer_sizes': (256, 256, 256), 'alpha': 0.1, 'activation': 'relu'}\n"
     ]
    }
   ],
   "source": [
    "#########################################################\n",
    "#################### SEPERATE RESULTS ###################\n",
    "\n",
    "results['MLP']['M1'] = {}\n",
    "results['MLP']['M1']['S'] = {}\n",
    "results['MLP']['M1']['L'] = {}\n",
    "results['MLP']['M1']['Com'] = {}\n",
    "\n",
    "####################### Hyperparameters #######################\n",
    "## get hyperparameters and fit models\n",
    "## short\n",
    "reg = MLPRegressor(random_state=42, max_iter=500, early_stopping=True)\n",
    "reg_gs = RandomizedSearchCV(reg, grid_MLP, random_state=42, cv=5, \n",
    "                            n_iter=50, scoring='neg_mean_squared_error')\n",
    "reg_gs.fit(X1_S,y_S)\n",
    "paramS = reg_gs.best_params_\n",
    "print(paramS)\n",
    "# Fit model\n",
    "regs = MLPRegressor(random_state=42, alpha=paramS['alpha'], \n",
    "                    hidden_layer_sizes=paramS['hidden_layer_sizes'],\n",
    "                    max_iter=500, early_stopping=True)\n",
    "regs.fit(X1_S,y_S)\n",
    "\n",
    "## long\n",
    "reg = MLPRegressor(random_state=42, max_iter=500, early_stopping=True)\n",
    "reg_gs = RandomizedSearchCV(reg, grid_MLP, random_state=42, cv=5, \n",
    "                            n_iter=50, scoring='neg_mean_squared_error')\n",
    "reg_gs.fit(X1_L,y_L)\n",
    "paramL = reg_gs.best_params_\n",
    "print(paramL)\n",
    "# Fit model\n",
    "regl = MLPRegressor(random_state=42, alpha=paramS['alpha'], \n",
    "                    hidden_layer_sizes=paramS['hidden_layer_sizes'],\n",
    "                    max_iter=500, early_stopping=True)\n",
    "regl.fit(X1_L,y_L)\n",
    "\n",
    "\n",
    "#################### Predictions and evaluate ####################\n",
    "########################### short\n",
    "## Predict\n",
    "y_test_predS = regs.predict(X1_S_test)\n",
    "y_train_predS = regs.predict(X1_S)\n",
    "\n",
    "## Get metrics  \n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(y_S_test,y_test_predS)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(y_S,y_train_predS)\n",
    "\n",
    "## Save results\n",
    "results['MLP']['M1']['S'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                              'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                              'rsq_train':r2_score(y_S, y_train_predS), \n",
    "                              'rsq_test':r2_score(y_S_test, y_test_predS),\n",
    "                              'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                              'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train}\n",
    "\n",
    "########################### long\n",
    "## predict\n",
    "y_test_predL = regl.predict(X1_L_test)\n",
    "y_train_predL = regl.predict(X1_L)\n",
    "\n",
    "## Get metrics  \n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(y_L_test,y_test_predL)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(y_L,y_train_predL)\n",
    "\n",
    "## Save results\n",
    "results['MLP']['M1']['L'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                              'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                              'rsq_train':r2_score(y_L, y_train_predL), \n",
    "                              'rsq_test':r2_score(y_L_test, y_test_predL),\n",
    "                              'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                              'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train}\n",
    "\n",
    "########################### combined\n",
    "y_com_real_test = pd.concat([y_S_test, y_L_test])\n",
    "y_com_pred_test = np.concatenate([y_test_predS,y_test_predL])\n",
    "y_com_real_train = pd.concat([y_S, y_L])\n",
    "y_com_pred_train = np.concatenate([y_train_predS,y_train_predL])\n",
    "\n",
    "## Get metrics  \n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(y_com_real_test,\n",
    "                                                                  y_com_pred_test)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(y_com_real_train,\n",
    "                                                                       y_com_pred_train)\n",
    "\n",
    "## Save results\n",
    "results['MLP']['M1']['Com'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                              'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                              'rsq_train':r2_score(y_com_real_train,y_com_pred_train), \n",
    "                              'rsq_test':r2_score(y_com_real_test,y_com_pred_test),\n",
    "                              'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                              'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "crazy-grace",
   "metadata": {},
   "source": [
    "#### MLP - M5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "addressed-baker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hidden_layer_sizes': 256, 'alpha': 10, 'activation': 'relu'}\n",
      "{'hidden_layer_sizes': (32, 32), 'alpha': 0.0001, 'activation': 'relu'}\n"
     ]
    }
   ],
   "source": [
    "#########################################################\n",
    "#################### SEPERATE RESULTS ###################\n",
    "\n",
    "results['MLP']['M5'] = {}\n",
    "results['MLP']['M5']['S'] = {}\n",
    "results['MLP']['M5']['L'] = {}\n",
    "results['MLP']['M5']['Com'] = {}\n",
    "\n",
    "####################### Hyperparameters #######################\n",
    "## get hyperparameters and fit models\n",
    "## short\n",
    "reg = MLPRegressor(random_state=42, max_iter=500, early_stopping=True)\n",
    "reg_gs = RandomizedSearchCV(reg, grid_MLP, random_state=42, cv=5, \n",
    "                            n_iter=50, scoring='neg_mean_squared_error')\n",
    "reg_gs.fit(X5_S,y_S)\n",
    "paramS = reg_gs.best_params_\n",
    "print(paramS)\n",
    "# Fit model\n",
    "regs = MLPRegressor(random_state=42, alpha=paramS['alpha'], \n",
    "                    hidden_layer_sizes=paramS['hidden_layer_sizes'],\n",
    "                    max_iter=500, early_stopping=True)\n",
    "regs.fit(X5_S,y_S)\n",
    "\n",
    "## long\n",
    "reg = MLPRegressor(random_state=42, max_iter=500, early_stopping=True)\n",
    "reg_gs = RandomizedSearchCV(reg, grid_MLP, random_state=42, cv=5, \n",
    "                            n_iter=50, scoring='neg_mean_squared_error')\n",
    "reg_gs.fit(X5_L,y_L)\n",
    "paramL = reg_gs.best_params_\n",
    "print(paramL)\n",
    "# Fit model\n",
    "regl = MLPRegressor(random_state=42, alpha=paramS['alpha'], \n",
    "                    hidden_layer_sizes=paramS['hidden_layer_sizes'],\n",
    "                    max_iter=500, early_stopping=True)\n",
    "regl.fit(X5_L,y_L)\n",
    "\n",
    "\n",
    "#################### Predictions and evaluate ####################\n",
    "########################### short\n",
    "## Predict\n",
    "y_test_predS = regs.predict(X5_S_test)\n",
    "y_train_predS = regs.predict(X5_S)\n",
    "\n",
    "## Get metrics  \n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(y_S_test,y_test_predS)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(y_S,y_train_predS)\n",
    "\n",
    "## Save results\n",
    "results['MLP']['M5']['S'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                              'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                              'rsq_train':r2_score(y_S, y_train_predS), \n",
    "                              'rsq_test':r2_score(y_S_test, y_test_predS),\n",
    "                              'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                              'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train}\n",
    "\n",
    "########################### long\n",
    "## predict\n",
    "y_test_predL = regl.predict(X5_L_test)\n",
    "y_train_predL = regl.predict(X5_L)\n",
    "\n",
    "## Get metrics  \n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(y_L_test,y_test_predL)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(y_L,y_train_predL)\n",
    "\n",
    "## Save results\n",
    "results['MLP']['M5']['L'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                              'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                              'rsq_train':r2_score(y_L, y_train_predL), \n",
    "                              'rsq_test':r2_score(y_L_test, y_test_predL),\n",
    "                              'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                              'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train}\n",
    "\n",
    "########################### combined\n",
    "y_com_real_test = pd.concat([y_S_test, y_L_test])\n",
    "y_com_pred_test = np.concatenate([y_test_predS,y_test_predL])\n",
    "y_com_real_train = pd.concat([y_S, y_L])\n",
    "y_com_pred_train = np.concatenate([y_train_predS,y_train_predL])\n",
    "\n",
    "## Get metrics  \n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(y_com_real_test,\n",
    "                                                                  y_com_pred_test)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(y_com_real_train,\n",
    "                                                                       y_com_pred_train)\n",
    "\n",
    "## Save results\n",
    "results['MLP']['M5']['Com'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                              'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                              'rsq_train':r2_score(y_com_real_train,y_com_pred_train), \n",
    "                              'rsq_test':r2_score(y_com_real_test,y_com_pred_test),\n",
    "                              'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                              'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "textile-parish",
   "metadata": {},
   "source": [
    "### GRADIANT BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "proof-verification",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_GB = {'max_depth':[2,3,5,10],'n_estimators':[100,300,500,1000], \n",
    "           'learning_rate':[0.001,0.01,0.1,0.5,0.9], 'min_samples_split':[2,3,5,7],\n",
    "           'min_samples_leaf':[3,5,10,15]}\n",
    "results['GB'] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-melbourne",
   "metadata": {},
   "source": [
    "#### Gradiant boosting - M1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "tribal-organizer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 100, 'min_samples_split': 7, 'min_samples_leaf': 15, 'max_depth': 2, 'learning_rate': 0.1}\n",
      "{'n_estimators': 300, 'min_samples_split': 7, 'min_samples_leaf': 10, 'max_depth': 3, 'learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "#########################################################\n",
    "#################### SEPERATE RESULTS ###################\n",
    "\n",
    "results['GB']['M1'] = {}\n",
    "results['GB']['M1']['S'] = {}\n",
    "results['GB']['M1']['L'] = {}\n",
    "results['GB']['M1']['Com'] = {}\n",
    "\n",
    "####################### Hyperparameters #######################\n",
    "## get hyperparameters\n",
    "# Short\n",
    "reg = GradientBoostingRegressor(random_state=42)\n",
    "reg_gs = RandomizedSearchCV(reg, grid_GB, random_state=42, cv=5, \n",
    "                            n_iter=50, scoring='neg_mean_squared_error')\n",
    "reg_gs.fit(X1_S,y_S)\n",
    "paramS = reg_gs.best_params_\n",
    "print(paramS)\n",
    "# Fit model\n",
    "regs = GradientBoostingRegressor(random_state=42, \n",
    "                                max_depth=paramS['max_depth'],\n",
    "                                n_estimators=paramS['n_estimators'], \n",
    "                                learning_rate=paramS['learning_rate'])\n",
    "regs.fit(X1_S,y_S)\n",
    "# Long\n",
    "reg = GradientBoostingRegressor(random_state=42)\n",
    "reg_gs = RandomizedSearchCV(reg, grid_GB, random_state=42, cv=5, \n",
    "                            n_iter=50, scoring='neg_mean_squared_error')\n",
    "reg_gs.fit(X1_L,y_L)\n",
    "paramL = reg_gs.best_params_\n",
    "print(paramL)\n",
    "regl = GradientBoostingRegressor(random_state=42, \n",
    "                                max_depth=paramL['max_depth'],\n",
    "                                n_estimators=paramL['n_estimators'], \n",
    "                                learning_rate=paramL['learning_rate'])\n",
    "regl.fit(X1_L,y_L)\n",
    "\n",
    "\n",
    "#################### Predictions and evaluate ####################\n",
    "########################### short\n",
    "## Predict\n",
    "y_test_predS = regs.predict(X1_S_test)\n",
    "y_train_predS = regs.predict(X1_S)\n",
    "\n",
    "## Get metrics  \n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(y_S_test,y_test_predS)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(y_S,y_train_predS)\n",
    "\n",
    "## Save results\n",
    "results['GB']['M1']['S'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                              'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                              'rsq_train':r2_score(y_S, y_train_predS), \n",
    "                              'rsq_test':r2_score(y_S_test, y_test_predS),\n",
    "                              'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                              'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train}\n",
    "\n",
    "########################### long\n",
    "## predict\n",
    "y_test_predL = regl.predict(X1_L_test)\n",
    "y_train_predL = regl.predict(X1_L)\n",
    "\n",
    "## Get metrics  \n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(y_L_test,y_test_predL)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(y_L,y_train_predL)\n",
    "\n",
    "## Save results\n",
    "results['GB']['M1']['L'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                              'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                              'rsq_train':r2_score(y_L, y_train_predL), \n",
    "                              'rsq_test':r2_score(y_L_test, y_test_predL),\n",
    "                              'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                              'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train}\n",
    "\n",
    "########################### combined\n",
    "y_com_real_test = pd.concat([y_S_test, y_L_test])\n",
    "y_com_pred_test = np.concatenate([y_test_predS,y_test_predL])\n",
    "y_com_real_train = pd.concat([y_S, y_L])\n",
    "y_com_pred_train = np.concatenate([y_train_predS,y_train_predL])\n",
    "\n",
    "## Get metrics  \n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(y_com_real_test,\n",
    "                                                                  y_com_pred_test)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(y_com_real_train,\n",
    "                                                                       y_com_pred_train)\n",
    "\n",
    "## Save results\n",
    "results['GB']['M1']['Com'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                              'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                              'rsq_train':r2_score(y_com_real_train,y_com_pred_train), \n",
    "                              'rsq_test':r2_score(y_com_real_test,y_com_pred_test),\n",
    "                              'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                              'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ahead-honey",
   "metadata": {},
   "source": [
    "#### GB - M5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "amended-surgery",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 300, 'min_samples_split': 7, 'min_samples_leaf': 10, 'max_depth': 3, 'learning_rate': 0.01}\n",
      "{'n_estimators': 300, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_depth': 2, 'learning_rate': 0.01}\n"
     ]
    }
   ],
   "source": [
    "#########################################################\n",
    "#################### SEPERATE RESULTS ###################\n",
    "\n",
    "results['GB']['M5'] = {}\n",
    "results['GB']['M5']['S'] = {}\n",
    "results['GB']['M5']['L'] = {}\n",
    "results['GB']['M5']['Com'] = {}\n",
    "\n",
    "####################### Hyperparameters #######################\n",
    "## get hyperparameters\n",
    "# Short\n",
    "reg = GradientBoostingRegressor(random_state=42)\n",
    "reg_gs = RandomizedSearchCV(reg, grid_GB, random_state=42, cv=5, \n",
    "                            n_iter=50, scoring='neg_mean_squared_error')\n",
    "reg_gs.fit(X5_S,y_S)\n",
    "paramS = reg_gs.best_params_\n",
    "print(paramS)\n",
    "# Fit model\n",
    "regs = GradientBoostingRegressor(random_state=42, \n",
    "                                max_depth=paramS['max_depth'],\n",
    "                                n_estimators=paramS['n_estimators'], \n",
    "                                learning_rate=paramS['learning_rate'])\n",
    "regs.fit(X5_S,y_S)\n",
    "# Long\n",
    "reg = GradientBoostingRegressor(random_state=42)\n",
    "reg_gs = RandomizedSearchCV(reg, grid_GB, random_state=42, cv=5, \n",
    "                            n_iter=50, scoring='neg_mean_squared_error')\n",
    "reg_gs.fit(X5_L,y_L)\n",
    "paramL = reg_gs.best_params_\n",
    "print(paramL)\n",
    "regl = GradientBoostingRegressor(random_state=42, \n",
    "                                max_depth=paramL['max_depth'],\n",
    "                                n_estimators=paramL['n_estimators'], \n",
    "                                learning_rate=paramL['learning_rate'])\n",
    "regl.fit(X5_L,y_L)\n",
    "\n",
    "\n",
    "#################### Predictions and evaluate ####################\n",
    "########################### short\n",
    "## Predict\n",
    "y_test_predS = regs.predict(X5_S_test)\n",
    "y_train_predS = regs.predict(X5_S)\n",
    "\n",
    "## Get metrics  \n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(y_S_test,y_test_predS)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(y_S,y_train_predS)\n",
    "\n",
    "## Save results\n",
    "results['GB']['M5']['S'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                              'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                              'rsq_train':r2_score(y_S, y_train_predS), \n",
    "                              'rsq_test':r2_score(y_S_test, y_test_predS),\n",
    "                              'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                              'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train}\n",
    "\n",
    "########################### long\n",
    "## predict\n",
    "y_test_predL = regl.predict(X5_L_test)\n",
    "y_train_predL = regl.predict(X5_L)\n",
    "\n",
    "## Get metrics  \n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(y_L_test,y_test_predL)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(y_L,y_train_predL)\n",
    "\n",
    "## Save results\n",
    "results['GB']['M5']['L'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                              'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                              'rsq_train':r2_score(y_L, y_train_predL), \n",
    "                              'rsq_test':r2_score(y_L_test, y_test_predL),\n",
    "                              'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                              'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train}\n",
    "\n",
    "########################### combined\n",
    "y_com_real_test = pd.concat([y_S_test, y_L_test])\n",
    "y_com_pred_test = np.concatenate([y_test_predS,y_test_predL])\n",
    "y_com_real_train = pd.concat([y_S, y_L])\n",
    "y_com_pred_train = np.concatenate([y_train_predS,y_train_predL])\n",
    "\n",
    "## Get metrics  \n",
    "MAE_test, RMSE_test, MSE_test, MAPE_test, NRMSE_test = test_model(y_com_real_test,\n",
    "                                                                  y_com_pred_test)\n",
    "MAE_train, RMSE_train, MSE_train, MAPE_train, NRMSE_train = test_model(y_com_real_train,\n",
    "                                                                       y_com_pred_train)\n",
    "\n",
    "## Save results\n",
    "results['GB']['M5']['Com'] = {'RMSE_train':RMSE_train,'RMSE_test':RMSE_test,\n",
    "                              'MAE_train': MAE_train,'MAE_test':MAE_test,\n",
    "                              'rsq_train':r2_score(y_com_real_train,y_com_pred_train), \n",
    "                              'rsq_test':r2_score(y_com_real_test,y_com_pred_test),\n",
    "                              'MAPE_test':MAPE_test,'MAPE_train':MAPE_train,\n",
    "                              'NRMSE_test':NRMSE_test,'NRMSE_train':NRMSE_train}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "backed-trade",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dried-zoning",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- SHORT --------------------\n",
      "LR - M1:\n",
      " R2: -0.05 RMSE: 409.0 MAE: 309.0 MAPE: 1931.0 NRMSE: 1.45\n",
      "LR - M5:\n",
      " R2: 0.0 RMSE: 399.0 MAE: 312.0 MAPE: 2025.0 NRMSE: 1.41\n",
      "\n",
      "\n",
      "RF - M1:\n",
      " R2: -0.0 RMSE: 399.0 MAE: 311.0 MAPE: 2000.0 NRMSE: 1.41\n",
      "RF - M5:\n",
      " R2: -0.03 RMSE: 405.0 MAE: 323.0 MAPE: 2224.0 NRMSE: 1.43\n",
      "\n",
      "\n",
      "MLP - M1:\n",
      " R2: 0.01 RMSE: 397.0 MAE: 310.0 MAPE: 2117.0 NRMSE: 1.41\n",
      "MLP - M5:\n",
      " R2: 0.01 RMSE: 397.0 MAE: 308.0 MAPE: 2011.0 NRMSE: 1.41\n",
      "\n",
      "\n",
      "GB - M1:\n",
      " R2: -0.0 RMSE: 399.0 MAE: 308.0 MAPE: 1994.0 NRMSE: 1.41\n",
      "GB - M5:\n",
      " R2: -0.02 RMSE: 403.0 MAE: 316.0 MAPE: 2113.0 NRMSE: 1.43\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "methods = ['LR', 'RF', 'MLP', 'GB']\n",
    "models = ['M1','M5']\n",
    "\n",
    "print(20*'-',\"SHORT\",20*'-')\n",
    "for me in methods:\n",
    "    for mo in models:\n",
    "        r = results[me][mo]['S']\n",
    "        RMSEtest = r['RMSE_test']\n",
    "        R2test = r['rsq_test']\n",
    "        MAEtest = r['MAE_test']\n",
    "        MAPE = r['MAPE_test']\n",
    "        NRMSE = r['NRMSE_test']\n",
    "        \n",
    "        print(\"{} - {}:\\n R2: {} RMSE: {} MAE: {} MAPE: {} NRMSE: {}\".format(me,mo,\n",
    "                                                                              round(np.mean(R2test),2),\n",
    "                                                                              round(np.mean(RMSEtest),0),\n",
    "                                                                              round(np.mean(MAEtest),0),\n",
    "                                                                              round(np.mean(MAPE),0),\n",
    "                                                                              round(np.mean(NRMSE),2)))        \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "durable-equipment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- LONG --------------------\n",
      "LR - M1:\n",
      " R2: -0.32 RMSE: 520.0 MAE: 397.0 MAPE: 1361.0 NRMSE: 0.69\n",
      "LR - M5:\n",
      " R2: -0.0 RMSE: 453.0 MAE: 338.0 MAPE: 1520.0 NRMSE: 0.61\n",
      "\n",
      "\n",
      "RF - M1:\n",
      " R2: 0.04 RMSE: 444.0 MAE: 326.0 MAPE: 1375.0 NRMSE: 0.59\n",
      "RF - M5:\n",
      " R2: 0.05 RMSE: 442.0 MAE: 322.0 MAPE: 1464.0 NRMSE: 0.59\n",
      "\n",
      "\n",
      "MLP - M1:\n",
      " R2: 0.02 RMSE: 448.0 MAE: 329.0 MAPE: 1379.0 NRMSE: 0.6\n",
      "MLP - M5:\n",
      " R2: 0.03 RMSE: 446.0 MAE: 327.0 MAPE: 1451.0 NRMSE: 0.6\n",
      "\n",
      "\n",
      "GB - M1:\n",
      " R2: 0.04 RMSE: 442.0 MAE: 324.0 MAPE: 1423.0 NRMSE: 0.59\n",
      "GB - M5:\n",
      " R2: 0.04 RMSE: 445.0 MAE: 322.0 MAPE: 1509.0 NRMSE: 0.59\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "methods = ['LR', 'RF', 'MLP', 'GB']\n",
    "models = ['M1','M5']\n",
    "\n",
    "print(20*'-',\"LONG\",20*'-')\n",
    "for me in methods:\n",
    "    for mo in models:\n",
    "        r = results[me][mo]['L']\n",
    "        RMSEtest = r['RMSE_test']\n",
    "        R2test = r['rsq_test']\n",
    "        MAEtest = r['MAE_test']\n",
    "        MAPE = r['MAPE_test']\n",
    "        NRMSE = r['NRMSE_test']\n",
    "        \n",
    "        print(\"{} - {}:\\n R2: {} RMSE: {} MAE: {} MAPE: {} NRMSE: {}\".format(me,mo,\n",
    "                                                                              round(np.mean(R2test),2),\n",
    "                                                                              round(np.mean(RMSEtest),0),\n",
    "                                                                              round(np.mean(MAEtest),0),\n",
    "                                                                              round(np.mean(MAPE),0),\n",
    "                                                                              round(np.mean(NRMSE),2)))        \n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "appropriate-abraham",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- COMBINED --------------------\n",
      "LR - M1:\n",
      " R2: 0.09 RMSE: 455.0 MAE: 343.0 MAPE: 1712.0 NRMSE: 0.99\n",
      "LR - M5:\n",
      " R2: 0.23 RMSE: 421.0 MAE: 322.0 MAPE: 1831.0 NRMSE: 0.91\n",
      "\n",
      "\n",
      "RF - M1:\n",
      " R2: 0.24 RMSE: 417.0 MAE: 316.0 MAPE: 1760.0 NRMSE: 0.9\n",
      "RF - M5:\n",
      " R2: 0.23 RMSE: 419.0 MAE: 323.0 MAPE: 1932.0 NRMSE: 0.91\n",
      "\n",
      "\n",
      "MLP - M1:\n",
      " R2: 0.24 RMSE: 417.0 MAE: 317.0 MAPE: 1833.0 NRMSE: 0.9\n",
      "MLP - M5:\n",
      " R2: 0.24 RMSE: 417.0 MAE: 315.0 MAPE: 1796.0 NRMSE: 0.9\n",
      "\n",
      "\n",
      "GB - M1:\n",
      " R2: 0.24 RMSE: 416.0 MAE: 314.0 MAPE: 1775.0 NRMSE: 0.9\n",
      "GB - M5:\n",
      " R2: 0.23 RMSE: 419.0 MAE: 318.0 MAPE: 1881.0 NRMSE: 0.91\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "methods = ['LR', 'RF', 'MLP', 'GB']\n",
    "models = ['M1','M5']\n",
    "\n",
    "print(20*'-',\"COMBINED\",20*'-')\n",
    "for me in methods:\n",
    "    for mo in models:\n",
    "        r = results[me][mo]['Com']\n",
    "        RMSEtest = r['RMSE_test']\n",
    "        R2test = r['rsq_test']\n",
    "        MAEtest = r['MAE_test']\n",
    "        MAPE = r['MAPE_test']\n",
    "        NRMSE = r['NRMSE_test']\n",
    "        \n",
    "        print(\"{} - {}:\\n R2: {} RMSE: {} MAE: {} MAPE: {} NRMSE: {}\".format(me,mo,\n",
    "                                                                              round(np.mean(R2test),2),\n",
    "                                                                              round(np.mean(RMSEtest),0),\n",
    "                                                                              round(np.mean(MAEtest),0),\n",
    "                                                                              round(np.mean(MAPE),0),\n",
    "                                                                              round(np.mean(NRMSE),2)))        \n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
